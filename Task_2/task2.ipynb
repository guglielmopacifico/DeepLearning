{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x15a4b6190>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from Common import NeuralNet\n",
    "import time\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.manual_seed(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pinns:\n",
    "    def __init__(self, n_int_, n_sb_, n_tb_, alpha_f_=0.005, h_f_=5, T_hot_=4, T_0_=1, U_f_=None):\n",
    "        self.n_int = n_int_     # n_int_:= number of intertior points\n",
    "        self.n_sb = n_sb_       # n_sb_ := number of spatial boundary points\n",
    "        self.n_tb = n_tb_       # n_tb_ := number of time boundary points\n",
    "\n",
    "        # Set the paremeters of the equation\n",
    "        self.alpha_f = alpha_f_\n",
    "        self.h_f = h_f_\n",
    "        self.T_hot = T_hot_\n",
    "        self.T_0 = T_0_\n",
    "        self.U_f = U_f_\n",
    "\n",
    "        # Extrema of the solution domain (t,x) in [0, t]x[0, L]\n",
    "        self.domain_extrema = torch.tensor([[0, 8],  # Time dimension\n",
    "                                            [0, 1]])  # Space dimension\n",
    "\n",
    "        # Number of space dimensions\n",
    "        self.space_dimensions = 1\n",
    "\n",
    "        # Parameter to balance role of data and PDE\n",
    "        self.lambda_u = 10\n",
    "\n",
    "        # FF Dense NN to approximate the solution of the underlying reaction-convection-diffusion equations of the fluid\n",
    "        self.approximate_solution = NeuralNet(input_dimension=self.domain_extrema.shape[0], output_dimension=1, # is a NN with input_dim=2 (time & space), output_dim=1 (fluid_temp)\n",
    "                                              n_hidden_layers=4,\n",
    "                                              neurons=20,\n",
    "                                              regularization_param=0.,\n",
    "                                              regularization_exp=2.,\n",
    "                                              retrain_seed=42)\n",
    "        \n",
    "        # FF Dense NN to approximate the solid temperature we wish to infer\n",
    "        self.approximate_coefficient = NeuralNet(input_dimension=self.domain_extrema.shape[0], output_dimension=1,  # is a NN with input_dim=2 (time & space), output_dim=1 (solid_temp)\n",
    "                                                 n_hidden_layers=4,\n",
    "                                                 neurons=20,\n",
    "                                                 regularization_param=0.,\n",
    "                                                 regularization_exp=2.,\n",
    "                                                 retrain_seed=42)\n",
    "\n",
    "        # Generator of Sobol sequences\n",
    "        self.soboleng = torch.quasirandom.SobolEngine(dimension=self.domain_extrema.shape[0])   # it will create a 2 cloumns tensor, the rows nunmber is specified after every time it is used\n",
    "\n",
    "        # Training sets S_sb, S_tb, S_int as torch dataloader\n",
    "        self.training_set_sb, self.training_set_tb, self.training_set_int, self.training_set_meas = self.assemble_datasets()\n",
    "\n",
    "    ################################################################################################\n",
    "    # Function to linearly transform a tensor whose value are between 0 and 1\n",
    "    # to a tensor whose values are between the domain extrema\n",
    "    def convert(self, tens):\n",
    "        assert (tens.shape[1] == self.domain_extrema.shape[0])\n",
    "        return tens * (self.domain_extrema[:, 1] - self.domain_extrema[:, 0]) + self.domain_extrema[:, 0]\n",
    "    \n",
    "    # Function Uf(t) -> given the time it gives back the velocity of the fluid in the relative phase\n",
    "    def fluid_velocity(self, inputs):\n",
    "        Uf = torch.full(inputs.shape, 999)  # give all 999 for semplicity when testing\n",
    "        \n",
    "        # \"\"\"QUI\"\"\"\n",
    "        # print(\"\\nfluid_velocity\")\n",
    "        # print('inputs: ', inputs.shape)\n",
    "\n",
    "        for i, t in enumerate(inputs):\n",
    "            # Charging Phase\n",
    "            if (t <= 1) or (t > 4 and t <=5 ): Uf[i] = 1\n",
    "            # Discharging Phase\n",
    "            elif (t > 2 and t <= 3) or (t > 6 and t <= 7): Uf[i] = -1\n",
    "            # Idle Phase\n",
    "            elif (t > 1 and t <= 2) or (t > 3 and t <= 4) or (t > 5 and t <= 6) or (t > 7 and t <= 8): Uf[i] = 0\n",
    "\n",
    "        return Uf\n",
    "    \n",
    "    ################################################################################################\n",
    "    # Function returning the input-output tensor required to assemble the training set S_tb corresponding to the temporal boundary\n",
    "    def add_temporal_boundary_points(self):\n",
    "        t0 = self.domain_extrema[0, 0]\n",
    "        input_tb = self.soboleng.draw(self.n_tb)    # input_sb has two columns (t, x) both with random numbers in the two respective domains\n",
    "        input_tb[:, 0] = torch.full(input_tb[:, 0].shape, t0)   # overwrite the entier column of time with t0\n",
    "        output_tb = torch.full(input_tb[:, 0].shape, self.T_0).reshape(-1, 1)   # the output has 1 column\n",
    "\n",
    "        # \"\"\"QUI\"\"\"\n",
    "        # print('ADD TEMPORAL BOUDARY POINTS:')\n",
    "        # print('input_tb: ', input_tb.shape)\n",
    "        # print('output_tb: ', output_tb.shape)\n",
    "\n",
    "        return input_tb, output_tb  # input_tb is the sequence of x_n; output_tb is the sequence u0(x_n)\n",
    "\n",
    "    # Function returning the input-output tensor required to assemble the training set S_sb corresponding to the spatial boundary\n",
    "    def add_spatial_boundary_points(self):\n",
    "        x0 = self.domain_extrema[1, 0]\n",
    "        xL = self.domain_extrema[1, 1]\n",
    "\n",
    "        # Dataset with random [t, x] both in [0, 1]\n",
    "        input_sb = self.soboleng.draw(self.n_sb)\n",
    "        \n",
    "        # requires the grad for these tensors as we will have to compute the derivatives\n",
    "        # just need to require it for this since using torch.clone will imply that also the new tensor will have it\n",
    "        input_sb.requires_grad_()\n",
    "\n",
    "        # Assigne the spacial boundary x=x0\n",
    "        input_sb_0 = torch.clone(input_sb)\n",
    "        input_sb_0[:, 1] = torch.full(input_sb_0[:, 1].shape, x0)\n",
    "\n",
    "        # Assigne the spacial boundary x=xL\n",
    "        input_sb_L = torch.clone(input_sb)\n",
    "        input_sb_L[:, 1] = torch.full(input_sb_L[:, 1].shape, xL)\n",
    "\n",
    "        # Def a tensor to add the delta in time to each of the input dataset and have the different phases\n",
    "        # This tenosr is full of [0, 0] and it will be filled on the t-column with the relative delta_t\n",
    "        delta_time = torch.zeros_like(input_sb)\n",
    "\n",
    "        # We are going now to define the input dataset for all the different phases over the 2 cycles.\n",
    "        # However, not that even if the input for the same phase over the 2 cycles is different (the t)\n",
    "        #Â the output is always the same (the spatial boundary conditions are the same), so we just need one output per phase.\n",
    "        \"\"\"Charging Phase\"\"\"\n",
    "        # First charging phase -> t in [0, 1] => delta_t=0\n",
    "        input_sb_0_charging_1 = torch.clone(input_sb_0)\n",
    "        input_sb_L_charging_1 = torch.clone(input_sb_L)\n",
    "        \n",
    "        # Second charging phase -> t in [4, 5] => delta_t=4\n",
    "        delta_time[:, 0] = torch.full(delta_time[:, 0].shape, 4)\n",
    "\n",
    "        input_sb_0_charging_2 = torch.clone(input_sb_0)\n",
    "        input_sb_0_charging_2 = input_sb_0_charging_2 + delta_time\n",
    "\n",
    "        input_sb_L_charging_2 = torch.clone(input_sb_L)\n",
    "        input_sb_L_charging_2 = input_sb_L_charging_2 + delta_time\n",
    "\n",
    "        # Output charging phase\n",
    "        output_sb_0_charging = torch.full(input_sb_0[:, 0].shape, self.T_hot).reshape(-1, 1)\n",
    "        output_sb_L_charging = torch.full(input_sb_L[:, 0].shape, 0).reshape(-1, 1)\n",
    "\n",
    "        \"\"\"Discharging Phase\"\"\"\n",
    "        # First discharging phase -> t in [2, 3] => delta_t=2\n",
    "        delta_time[:, 0] = torch.full(delta_time[:, 0].shape, 2)\n",
    "\n",
    "        input_sb_0_discharging_1 = torch.clone(input_sb_0)\n",
    "        input_sb_0_discharging_1 = input_sb_0_discharging_1 + delta_time\n",
    "\n",
    "        input_sb_L_discharging_1 = torch.clone(input_sb_L)\n",
    "        input_sb_L_discharging_1 = input_sb_L_discharging_1 + delta_time\n",
    "\n",
    "        # Second discharging phase -> t in [6, 7] => delta_t=6\n",
    "        delta_time[:, 0] = torch.full(delta_time[:, 0].shape, 6)\n",
    "\n",
    "        input_sb_0_discharging_2 = torch.clone(input_sb_0)\n",
    "        input_sb_0_discharging_2 = input_sb_0_discharging_2 + delta_time\n",
    "\n",
    "        input_sb_L_discharging_2 = torch.clone(input_sb_L)\n",
    "        input_sb_L_discharging_2 = input_sb_L_discharging_2 + delta_time\n",
    "\n",
    "        # Output discharging phase\n",
    "        output_sb_0_discharging = torch.full(input_sb_0[:, 0].shape, 0).reshape(-1, 1)\n",
    "        output_sb_L_discharging = torch.full(input_sb_L[:, 0].shape, self.T_0).reshape(-1, 1)\n",
    "\n",
    "\n",
    "        \"\"\"Idle Phase\"\"\"\n",
    "        # First idle phase -> t in [1, 2] => delta_t=1\n",
    "        delta_time[:, 0] = torch.full(delta_time[:, 0].shape, 1)\n",
    "\n",
    "        input_sb_0_idle_1 = torch.clone(input_sb_0)\n",
    "        input_sb_0_idle_1 = input_sb_0_idle_1 + delta_time\n",
    "\n",
    "        input_sb_L_idle_1 = torch.clone(input_sb_L)\n",
    "        input_sb_L_idle_1 = input_sb_L_idle_1 + delta_time\n",
    "\n",
    "        # Second idle phase -> t in [3, 4] => delta_t=3\n",
    "        delta_time[:, 0] = torch.full(delta_time[:, 0].shape, 3)\n",
    "\n",
    "        input_sb_0_idle_2 = torch.clone(input_sb_0)\n",
    "        input_sb_0_idle_2 = input_sb_0_idle_2 + delta_time\n",
    "\n",
    "        input_sb_L_idle_2 = torch.clone(input_sb_L)\n",
    "        input_sb_L_idle_2 = input_sb_L_idle_2 + delta_time\n",
    "\n",
    "        # Third idle phase -> t in [5, 6] => delta_t=5\n",
    "        delta_time[:, 0] = torch.full(delta_time[:, 0].shape, 5)\n",
    "\n",
    "        input_sb_0_idle_3 = torch.clone(input_sb_0)\n",
    "        input_sb_0_idle_3 = input_sb_0_idle_3 + delta_time\n",
    "\n",
    "        input_sb_L_idle_3 = torch.clone(input_sb_L)\n",
    "        input_sb_L_idle_3 = input_sb_L_idle_3 + delta_time\n",
    "\n",
    "        # Fourth idle phase -> t in [7, 8] => delta_t=7\n",
    "        delta_time[:, 0] = torch.full(delta_time[:, 0].shape, 7)\n",
    "\n",
    "        input_sb_0_idle_4 = torch.clone(input_sb_0)\n",
    "        input_sb_0_idle_4 = input_sb_0_idle_4 + delta_time\n",
    "\n",
    "        input_sb_L_idle_4 = torch.clone(input_sb_L)\n",
    "        input_sb_L_idle_4 = input_sb_L_idle_4 + delta_time\n",
    "\n",
    "        # Output idle phase\n",
    "        output_sb_0_idle = torch.full(input_sb_0[:, 0].shape, 0).reshape(-1, 1)\n",
    "        output_sb_L_idle = torch.full(input_sb_L[:, 0].shape, 0).reshape(-1, 1)\n",
    "\n",
    "        # \"\"\"QUI\"\"\"\n",
    "        # print('CYCLE 1:')\n",
    "        # print('input_sb_0_charging_1: ', input_sb_0_charging_1.shape)\n",
    "        # print('input_sb_L_charging_1: ', input_sb_L_charging_1.shape)\n",
    "        # print('input_sb_0_idle_1: ', input_sb_0_idle_1.shape)\n",
    "        # print('input_sb_L_idle_1: ', input_sb_L_idle_1.shape)\n",
    "        # print('input_sb_0_discharging_1: ', input_sb_0_discharging_1.shape)\n",
    "        # print('input_sb_L_discharging_1: ', input_sb_L_discharging_1.shape)\n",
    "        # print('input_sb_0_idle_2: ', input_sb_0_idle_2.shape)\n",
    "        # print('input_sb_L_idle_2: ', input_sb_L_idle_2.shape)\n",
    "        # print('\\nCYCLE 2:')\n",
    "        # print('input_sb_0_charging_2: ', input_sb_0_charging_2.shape)\n",
    "        # print('input_sb_L_charging_2: ', input_sb_L_charging_2.shape)\n",
    "        # print('input_sb_0_idle_3: ', input_sb_0_idle_3.shape)\n",
    "        # print('input_sb_L_idle_3: ', input_sb_L_idle_3.shape)\n",
    "        # print('input_sb_0_discharging_2: ', input_sb_0_discharging_2.shape)\n",
    "        # print('input_sb_L_discharging_2: ', input_sb_L_discharging_2.shape)\n",
    "        # print('input_sb_0_idle_4: ', input_sb_0_idle_4.shape)\n",
    "        # print('input_sb_L_idle_4: ', input_sb_L_idle_4.shape)\n",
    "        # print('\\nOUTPUT:')\n",
    "        # print('output_sb_0_charging: ', output_sb_0_charging.shape)\n",
    "        # print('output_sb_L_charging: ', output_sb_L_charging.shape)\n",
    "        # print('output_sb_0_idle: ', output_sb_0_idle.shape)\n",
    "        # print('output_sb_L_idle: ', output_sb_L_idle.shape)\n",
    "        # print('output_sb_0_discharging: ', output_sb_0_discharging.shape)\n",
    "        # print('output_sb_L_discharging: ', output_sb_L_discharging.shape)\n",
    "        \n",
    "        return torch.cat([  # cycle 1\n",
    "                        input_sb_0_charging_1, input_sb_L_charging_1,\n",
    "                        input_sb_0_idle_1, input_sb_L_idle_1,\n",
    "                        input_sb_0_discharging_1, input_sb_L_discharging_1,\n",
    "                        input_sb_0_idle_2, input_sb_L_idle_2,\n",
    "                            # cycle 2\n",
    "                        input_sb_0_charging_2, input_sb_L_charging_2,\n",
    "                        input_sb_0_idle_3, input_sb_L_idle_3,\n",
    "                        input_sb_0_discharging_2, input_sb_L_discharging_2,\n",
    "                        input_sb_0_idle_4, input_sb_L_idle_4\n",
    "                        ], 0), torch.cat([  # cycle 1\n",
    "                                        output_sb_0_charging, output_sb_L_charging,\n",
    "                                        output_sb_0_idle, output_sb_L_idle,\n",
    "                                        output_sb_0_discharging, output_sb_L_discharging,\n",
    "                                        output_sb_0_idle, output_sb_L_idle,\n",
    "                                            # cycle 2\n",
    "                                        output_sb_0_charging, output_sb_L_charging,\n",
    "                                        output_sb_0_idle, output_sb_L_idle,\n",
    "                                        output_sb_0_discharging, output_sb_L_discharging,\n",
    "                                        output_sb_0_idle, output_sb_L_idle\n",
    "                                        ], 0)\n",
    "\n",
    "    # Function returning the input-output tensor required to assemble the training set S_int corresponding to the interior domain where the PDE is enforced\n",
    "    def add_interior_points(self):\n",
    "        # Now we use the convert fct since we want the t is in [0, 8]\n",
    "        input_int = self.convert(self.soboleng.draw(self.n_int))\n",
    "        output_int = torch.zeros((input_int.shape[0], 1))\n",
    "        \n",
    "        return input_int, output_int\n",
    "    \n",
    "    # Function returning the input-output tensor required to assemble the training set S_meas corresponding to the measured points in the domain.\n",
    "    # These points are read from the file \"DataSolution.txt\"\n",
    "    def get_measurement_data(self):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df_meas = pd.read_csv('DataSolution.txt')\n",
    "\n",
    "        # Convert the DataFrame to a torch.tensor\n",
    "        tensor_meas = torch.tensor(df_meas.values , dtype=torch.float)\n",
    "        \n",
    "        # The first 2 columns are the inputs: [t, x]\n",
    "        input_meas = tensor_meas[:, :2]\n",
    "        \n",
    "        # The last column are the outputs: [Tf]\n",
    "        output_meas = tensor_meas[:, 2:]\n",
    "        return input_meas, output_meas\n",
    "\n",
    "    # Function returning the training sets S_sb, S_tb, S_int as dataloader\n",
    "    def assemble_datasets(self):\n",
    "        input_sb, output_sb = self.add_spatial_boundary_points()    # S_sb\n",
    "        input_tb, output_tb = self.add_temporal_boundary_points()   # S_tb\n",
    "        input_int, output_int = self.add_interior_points()          # S_int\n",
    "        input_meas, output_meas = self.get_measurement_data()       # S_meas\n",
    "\n",
    "        # \"\"\"QUI\"\"\"\n",
    "        # print('\\nSONO IN assemble_datasets:')\n",
    "        # print('input_sb', input_sb.shape)\n",
    "        # print('output_sb', output_sb.shape)\n",
    "        # print()\n",
    "        # print('input_tb', input_tb.shape)\n",
    "        # print('output_tb', output_tb.shape)\n",
    "        # print()\n",
    "        # print('input_int', input_int.shape)\n",
    "        # print('output_int', output_int.shape)\n",
    "        # print()\n",
    "        # print('input_meas', input_meas.shape)\n",
    "        # print('output_meas', output_meas.shape)\n",
    "        # print()\n",
    "\n",
    "        training_set_sb = DataLoader(torch.utils.data.TensorDataset(input_sb, output_sb), batch_size=16*self.space_dimensions*self.n_sb, shuffle=False)  #batch_size has *8 since there are 8 different phases and for each one we have 2 conditions (x0 & xL)\n",
    "        training_set_tb = DataLoader(torch.utils.data.TensorDataset(input_tb, output_tb), batch_size=self.n_tb, shuffle=False)\n",
    "        training_set_int = DataLoader(torch.utils.data.TensorDataset(input_int, output_int), batch_size=self.n_int, shuffle=False)\n",
    "        training_set_meas = DataLoader(torch.utils.data.TensorDataset(input_meas, output_meas), batch_size=output_meas.shape[0], shuffle=False)\n",
    "\n",
    "        return training_set_sb, training_set_tb, training_set_int, training_set_meas\n",
    "\n",
    "    ################################################################################################\n",
    "    # Function to compute the terms required in the definition of the TEMPORAL boundary residual\n",
    "    def apply_initial_condition(self, input_tb):\n",
    "        u_pred_tb = self.approximate_solution(input_tb)\n",
    "        \n",
    "        return u_pred_tb\n",
    "\n",
    "    # Function to compute the terms required in the definition of the SPATIAL boundary residual\n",
    "    def apply_boundary_conditions(self, input_sb):\n",
    "        # input_tb is a tensor of size [16*self.n_sb, 2]\n",
    "        # as defined in \"add_spatial_boundary_points\" we have 2 boundary conditions for each phase\n",
    "        # we then have to devide the input_sb in 16\n",
    "        assert (input_sb.requires_grad==True)   # make sure the grad is requested so we can compute the derivatives\n",
    "\n",
    "        # Devide all the input datasets\n",
    "            # cycle 1\n",
    "        input_sb_0_charging_1 = input_sb[:int(input_sb.shape[0]/16), :]\n",
    "        input_sb_L_charging_1 = input_sb[int(input_sb.shape[0]/16):2*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_0_idle_1 = input_sb[2*int(input_sb.shape[0]/16):3*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_L_idle_1 = input_sb[3*int(input_sb.shape[0]/16):4*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_0_discharging_1 = input_sb[4*int(input_sb.shape[0]/16):5*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_L_discharging_1 = input_sb[5*int(input_sb.shape[0]/16):6*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_0_idle_2 = input_sb[6*int(input_sb.shape[0]/16):7*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_L_idle_2 = input_sb[7*int(input_sb.shape[0]/16):8*int(input_sb.shape[0]/16), :]\n",
    "            # cycle 2\n",
    "        input_sb_0_charging_2 = input_sb[8*int(input_sb.shape[0]/16):9*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_L_charging_2 = input_sb[9*int(input_sb.shape[0]/16):10*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_0_idle_3 = input_sb[10*int(input_sb.shape[0]/16):11*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_L_idle_3 = input_sb[11*int(input_sb.shape[0]/16):12*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_0_discharging_2 = input_sb[12*int(input_sb.shape[0]/16):13*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_L_discharging_2 = input_sb[13*int(input_sb.shape[0]/16):14*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_0_idle_4 = input_sb[14*int(input_sb.shape[0]/16):15*int(input_sb.shape[0]/16), :]\n",
    "        input_sb_L_idle_4 = input_sb[15*int(input_sb.shape[0]/16):, :]\n",
    "\n",
    "        \"\"\"Charging Phase\"\"\"\n",
    "        # First charging phase\n",
    "            # x0 -> compute Tf\n",
    "        u_pred_sb_0_charging_1 = self.approximate_solution(input_sb_0_charging_1).reshape(-1, 1)\n",
    "\n",
    "            # xL -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_L_charging_1)\n",
    "        u_pred_sb_L_charging_1 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_L_charging_1, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "\n",
    "        # Second charging phase\n",
    "            # x0 -> compute Tf\n",
    "        u_pred_sb_0_charging_2 = self.approximate_solution(input_sb_0_charging_2).reshape(-1, 1)\n",
    "\n",
    "            # xL -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_L_charging_2)\n",
    "        u_pred_sb_L_charging_2 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_L_charging_2, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "\n",
    "        \"\"\"Discharging Phase\"\"\"\n",
    "        # First discharging phase\n",
    "            # x0 -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_0_discharging_1)\n",
    "        u_pred_sb_0_discharging_1 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_0_discharging_1, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "        \n",
    "            # xL -> compute Tf\n",
    "        u_pred_sb_L_discharging_1 = self.approximate_solution(input_sb_L_discharging_1).reshape(-1, 1)\n",
    "\n",
    "        # Second discharging phase\n",
    "            # x0 -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_0_discharging_2)\n",
    "        u_pred_sb_0_discharging_2 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_0_discharging_2, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "        \n",
    "            # xL -> compute Tf\n",
    "        u_pred_sb_L_discharging_2 = self.approximate_solution(input_sb_L_discharging_2).reshape(-1, 1)\n",
    "\n",
    "        \"\"\"Idle Phase\"\"\"\n",
    "        # First idle phase\n",
    "            # x0 -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_0_idle_1)\n",
    "        u_pred_sb_0_idle_1 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_0_idle_1, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "\n",
    "            # xL -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_L_idle_1)\n",
    "        u_pred_sb_L_idle_1 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_L_idle_1, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "\n",
    "        # Second idle phase\n",
    "            # x0 -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_0_idle_2)\n",
    "        u_pred_sb_0_idle_2 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_0_idle_2, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "\n",
    "            # xL -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_L_idle_2)\n",
    "        u_pred_sb_L_idle_2 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_L_idle_2, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "\n",
    "        # Third idle phase\n",
    "            # x0 -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_0_idle_3)\n",
    "        u_pred_sb_0_idle_3 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_0_idle_3, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "\n",
    "            # xL -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_L_idle_3)\n",
    "        u_pred_sb_L_idle_3 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_L_idle_3, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "\n",
    "        # Fourth idle phase\n",
    "            # x0 -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_0_idle_4)\n",
    "        u_pred_sb_0_idle_4 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_0_idle_4, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "\n",
    "            # xL -> compute dTf/dx\n",
    "        u_pred_Tf = self.approximate_solution(input_sb_L_idle_4)\n",
    "        u_pred_sb_L_idle_4 = torch.autograd.grad(u_pred_Tf.sum(), input_sb_L_idle_4, create_graph=True)[0][:, 1].reshape(-1, 1) # take only d/dx\n",
    "        \n",
    "        # \"\"\"QUI\"\"\"\n",
    "        # print('CYCLE 1:')\n",
    "        # print('u_pred_sb_0_charging_1: ', u_pred_sb_0_charging_1.shape)\n",
    "        # print('u_pred_sb_L_charging_1: ', u_pred_sb_L_charging_1.shape)\n",
    "        # print('u_pred_sb_0_idle_1: ', u_pred_sb_0_idle_1.shape)\n",
    "        # print('u_pred_sb_L_idle_1: ', u_pred_sb_L_idle_1.shape)\n",
    "        # print('u_pred_sb_0_discharging_1: ', u_pred_sb_0_discharging_1.shape)\n",
    "        # print('u_pred_sb_L_discharging_1: ', u_pred_sb_L_discharging_1.shape)\n",
    "        # print('u_pred_sb_0_idle_2: ', u_pred_sb_0_idle_2.shape)\n",
    "        # print('u_pred_sb_L_idle_2: ', u_pred_sb_L_idle_2.shape)\n",
    "        # print('\\nCYCLE 2:')\n",
    "        # print('u_pred_sb_0_charging_2: ', u_pred_sb_0_charging_2.shape)\n",
    "        # print('u_pred_sb_L_charging_2: ', u_pred_sb_L_charging_2.shape)\n",
    "        # print('u_pred_sb_0_idle_3: ', u_pred_sb_0_idle_3.shape)\n",
    "        # print('u_pred_sb_L_idle_3: ', u_pred_sb_L_idle_3.shape)\n",
    "        # print('u_pred_sb_0_discharging_2: ', u_pred_sb_0_discharging_2.shape)\n",
    "        # print('u_pred_sb_L_discharging_2: ', u_pred_sb_L_discharging_2.shape)\n",
    "        # print('u_pred_sb_0_idle_4: ', u_pred_sb_0_idle_4.shape)\n",
    "        # print('u_pred_sb_L_idle_4: ', u_pred_sb_L_idle_4.shape)\n",
    "\n",
    "        return torch.cat([  # cycle 1\n",
    "                        u_pred_sb_0_charging_1, u_pred_sb_L_charging_1,\n",
    "                        u_pred_sb_0_idle_1, u_pred_sb_L_idle_1,\n",
    "                        u_pred_sb_0_discharging_1, u_pred_sb_L_discharging_1,\n",
    "                        u_pred_sb_0_idle_2, u_pred_sb_L_idle_2,\n",
    "                            # cycle 2\n",
    "                        u_pred_sb_0_charging_2, u_pred_sb_L_charging_2,\n",
    "                        u_pred_sb_0_idle_3, u_pred_sb_L_idle_3,\n",
    "                        u_pred_sb_0_discharging_2, u_pred_sb_L_discharging_2,\n",
    "                        u_pred_sb_0_idle_4, u_pred_sb_L_idle_4\n",
    "                        ], 0)\n",
    "\n",
    "    # Function to compute the PDE residuals\n",
    "    def compute_pde_residual(self, input_int):\n",
    "        input_int.requires_grad = True\n",
    "        u = self.approximate_solution(input_int).reshape(-1,)       # u is the solution (Tf) of the PDE\n",
    "        g = self.approximate_coefficient(input_int).reshape(-1,)    # g is the function (Ts) that is requested\n",
    "\n",
    "        # grad compute the gradient of a \"SCALAR\" function L with respect to some input nxm TENSOR Z=[[x1, y1],[x2,y2],[x3,y3],...,[xn,yn]], m=2\n",
    "        # it returns grad_L = [[dL/dx1, dL/dy1],[dL/dx2, dL/dy2],[dL/dx3, dL/dy3],...,[dL/dxn, dL/dyn]]\n",
    "        # Note: pytorch considers a tensor [u1, u2,u3, ... ,un] a vectorial function\n",
    "        # whereas sum_u = u1 + u2 + u3 + u4 + ... + un as a \"scalar\" one\n",
    "\n",
    "        # In our case ui = u(xi), therefore the line below returns:\n",
    "        # grad_u = [[dsum_u/dx1, dsum_u/dy1],[dsum_u/dx2, dsum_u/dy2],[dsum_u/dx3, dL/dy3],...,[dsum_u/dxm, dsum_u/dyn]]\n",
    "        # and dsum_u/dxi = d(u1 + u2 + u3 + u4 + ... + un)/dxi = d(u(x1) + u(x2) u3(x3) + u4(x4) + ... + u(xn))/dxi = dui/dxi\n",
    "\n",
    "        # Since u for us is u = (uf, us), we have to devide the two cases\n",
    "\n",
    "        grad_u = torch.autograd.grad(u.sum(), input_int, create_graph=True)[0]\n",
    "        grad_u_t = grad_u[:, 0]\n",
    "        grad_u_x = grad_u[:, 1]\n",
    "        grad_u_xx = torch.autograd.grad(grad_u_x.sum(), input_int, create_graph=True)[0][:, 1]\n",
    "\n",
    "        # Compute the velocity of the fluid Uf(t)\n",
    "        Uf = self.fluid_velocity(input_int[:, 0])\n",
    "\n",
    "        residual = (grad_u_t + Uf*grad_u_x) - (self.alpha_f*grad_u_xx - self.h_f*(u-g))\n",
    "\n",
    "        return residual.reshape(-1, )\n",
    "\n",
    "    # Function to compute the total loss (weighted sum of spatial boundary loss, temporal boundary loss and interior loss)\n",
    "    def compute_loss(self, inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, inp_train_meas, u_train_meas, verbose=True):\n",
    "        u_pred_sb = self.apply_boundary_conditions(inp_train_sb)\n",
    "        u_pred_tb = self.apply_initial_condition(inp_train_tb)\n",
    "        u_pred_meas = self.approximate_solution(inp_train_meas)\n",
    "\n",
    "        assert (u_pred_sb.shape[1] == u_train_sb.shape[1])\n",
    "        assert (u_pred_tb.shape[1] == u_train_tb.shape[1])\n",
    "        assert (u_pred_meas.shape[1] == u_train_meas.shape[1])\n",
    "\n",
    "\n",
    "        r_int = self.compute_pde_residual(inp_train_int)\n",
    "        r_sb = u_train_sb - u_pred_sb\n",
    "        r_tb = u_train_tb - u_pred_tb\n",
    "        r_meas = u_train_meas - u_pred_meas\n",
    "\n",
    "        loss_sb = torch.mean(abs(r_sb) ** 2)\n",
    "        loss_tb = torch.mean(abs(r_tb) ** 2)\n",
    "        loss_int = torch.mean(abs(r_int) ** 2)\n",
    "        loss_meas = torch.mean(abs(r_meas) ** 2)\n",
    "\n",
    "        loss_u = loss_sb + loss_tb + loss_meas\n",
    "\n",
    "        loss = torch.log10(self.lambda_u * loss_u + loss_int)\n",
    "        if verbose: print(\"Total loss: \", round(loss.item(), 4), \"| PDE Loss: \", round(torch.log10(loss_int).item(), 4), \"| Function Loss: \", round(torch.log10(loss_u).item(), 4))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    ################################################################################################\n",
    "    def fit(self, num_epochs, optimizer, verbose=True):\n",
    "        history = list()\n",
    "\n",
    "        # Loop over epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            if verbose: print(\"################################ \", epoch, \" ################################\")\n",
    "\n",
    "            for j, ((inp_train_sb, u_train_sb), (inp_train_tb, u_train_tb), (inp_train_int, u_train_int), (inp_train_meas, u_train_meas)) in enumerate(zip(self.training_set_sb, self.training_set_tb, self.training_set_int, self.training_set_meas)):\n",
    "                def closure():\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = self.compute_loss(inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, inp_train_meas, u_train_meas, verbose=verbose)\n",
    "                    loss.backward(create_graph=True)\n",
    "\n",
    "                    history.append(loss.item())\n",
    "                    return loss\n",
    "                \n",
    "                optimizer.step(closure=closure)\n",
    "\n",
    "        print('Final Loss: ', history[-1])\n",
    "\n",
    "        return history\n",
    "\n",
    "    ################################################################################################\n",
    "    def plotting(self):\n",
    "        inputs = self.soboleng.draw(100000)\n",
    "\n",
    "        output = self.approximate_solution(inputs).reshape(-1, )\n",
    "        exact_output = self.exact_solution(inputs).reshape(-1, )\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(16, 8), dpi=150)\n",
    "        im1 = axs[0].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=exact_output.detach(), cmap=\"jet\")\n",
    "        axs[0].set_xlabel(\"x\")\n",
    "        axs[0].set_ylabel(\"t\")\n",
    "        plt.colorbar(im1, ax=axs[0])\n",
    "        axs[0].grid(True, which=\"both\", ls=\":\")\n",
    "        im2 = axs[1].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=output.detach(), cmap=\"jet\")\n",
    "        axs[1].set_xlabel(\"x\")\n",
    "        axs[1].set_ylabel(\"t\")\n",
    "        plt.colorbar(im2, ax=axs[1])\n",
    "        axs[1].grid(True, which=\"both\", ls=\":\")\n",
    "        axs[0].set_title(\"Exact Solution\")\n",
    "        axs[1].set_title(\"Approximate Solution\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        err = (torch.mean((output - exact_output) ** 2) / torch.mean(exact_output ** 2)) ** 0.5 * 100\n",
    "        print(\"L2 Relative Error Norm: \", err.item(), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_int = 256\n",
    "n_sb = 64\n",
    "n_tb = 64\n",
    "\n",
    "pinn = Pinns(n_int, n_sb, n_tb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uf(t): fluid velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate some points for the time in [0, 8]\n",
    "input_time = torch.linspace(0, 8, 1000, dtype=torch.float).reshape(-1, 1)\n",
    "\n",
    "Uf = pinn.fluid_velocity(input_time)\n",
    "\n",
    "plt.figure(figsize=(16, 8), dpi=150)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(input_time.detach().numpy(), Uf.detach().numpy())\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Uf\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "optimizer_LBFGS = optim.LBFGS(pinn.approximate_solution.parameters(),\n",
    "                              lr=float(0.5),\n",
    "                              max_iter=50000,\n",
    "                              max_eval=50000,\n",
    "                              history_size=150,\n",
    "                              line_search_fn=\"strong_wolfe\",\n",
    "                              tolerance_change=1.0 * np.finfo(float).eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################  0  ################################\n",
      "Total loss:  1.6793 | PDE Loss:  -0.3163 | Function Loss:  0.6749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gugo/opt/anaconda3/envs/MasterThesis/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1678454847243/work/torch/csrc/autograd/engine.cpp:1156.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss:  1.6168 | PDE Loss:  -0.0046 | Function Loss:  0.6063\n",
      "Total loss:  1.5052 | PDE Loss:  0.8768 | Function Loss:  0.3888\n",
      "Total loss:  1.5016 | PDE Loss:  0.8593 | Function Loss:  0.3892\n",
      "Total loss:  1.4844 | PDE Loss:  0.811 | Function Loss:  0.3809\n",
      "Total loss:  1.4723 | PDE Loss:  0.7511 | Function Loss:  0.3808\n",
      "Total loss:  1.4654 | PDE Loss:  0.7543 | Function Loss:  0.3715\n",
      "Total loss:  1.4593 | PDE Loss:  0.6293 | Function Loss:  0.3898\n",
      "Total loss:  1.4549 | PDE Loss:  0.6921 | Function Loss:  0.3725\n",
      "Total loss:  1.4524 | PDE Loss:  0.7313 | Function Loss:  0.3608\n",
      "Total loss:  1.4502 | PDE Loss:  0.7625 | Function Loss:  0.3504\n",
      "Total loss:  1.4478 | PDE Loss:  0.786 | Function Loss:  0.3411\n",
      "Total loss:  1.445 | PDE Loss:  0.7981 | Function Loss:  0.3341\n",
      "Total loss:  1.4412 | PDE Loss:  0.7966 | Function Loss:  0.3295\n",
      "Total loss:  1.4358 | PDE Loss:  0.7844 | Function Loss:  0.3262\n",
      "Total loss:  1.4293 | PDE Loss:  0.7658 | Function Loss:  0.323\n",
      "Total loss:  1.4231 | PDE Loss:  0.7479 | Function Loss:  0.32\n",
      "Total loss:  1.4184 | PDE Loss:  0.7375 | Function Loss:  0.3168\n",
      "Total loss:  1.4152 | PDE Loss:  0.7468 | Function Loss:  0.3103\n",
      "Total loss:  1.4136 | PDE Loss:  0.7455 | Function Loss:  0.3086\n",
      "Total loss:  1.4112 | PDE Loss:  0.7527 | Function Loss:  0.3036\n",
      "Total loss:  1.4082 | PDE Loss:  0.7397 | Function Loss:  0.3033\n",
      "Total loss:  1.4052 | PDE Loss:  0.7886 | Function Loss:  0.2851\n",
      "Total loss:  1.4033 | PDE Loss:  0.7685 | Function Loss:  0.2888\n",
      "Total loss:  1.4008 | PDE Loss:  0.7418 | Function Loss:  0.2933\n",
      "Total loss:  1.3974 | PDE Loss:  0.7019 | Function Loss:  0.2996\n",
      "Total loss:  1.3953 | PDE Loss:  0.6843 | Function Loss:  0.3014\n",
      "Total loss:  1.3934 | PDE Loss:  0.6953 | Function Loss:  0.2963\n",
      "Total loss:  1.3918 | PDE Loss:  0.7153 | Function Loss:  0.2891\n",
      "Total loss:  1.391 | PDE Loss:  0.7237 | Function Loss:  0.2858\n",
      "Total loss:  1.3898 | PDE Loss:  0.7278 | Function Loss:  0.2832\n",
      "Total loss:  1.3877 | PDE Loss:  0.7305 | Function Loss:  0.2797\n",
      "Total loss:  1.3842 | PDE Loss:  0.7315 | Function Loss:  0.275\n",
      "Total loss:  1.3796 | PDE Loss:  0.7382 | Function Loss:  0.267\n",
      "Total loss:  1.3733 | PDE Loss:  0.6844 | Function Loss:  0.2738\n",
      "Total loss:  1.3702 | PDE Loss:  0.6947 | Function Loss:  0.2672\n",
      "Total loss:  1.3684 | PDE Loss:  0.689 | Function Loss:  0.2664\n",
      "Total loss:  1.3659 | PDE Loss:  0.712 | Function Loss:  0.257\n",
      "Total loss:  1.3639 | PDE Loss:  0.6892 | Function Loss:  0.2607\n",
      "Total loss:  1.3622 | PDE Loss:  0.701 | Function Loss:  0.2553\n",
      "Total loss:  1.3595 | PDE Loss:  0.7057 | Function Loss:  0.2505\n",
      "Total loss:  1.3558 | PDE Loss:  0.704 | Function Loss:  0.2463\n",
      "Total loss:  1.352 | PDE Loss:  0.6903 | Function Loss:  0.2453\n",
      "Total loss:  1.3486 | PDE Loss:  0.6978 | Function Loss:  0.2388\n",
      "Total loss:  1.3468 | PDE Loss:  0.6179 | Function Loss:  0.257\n",
      "Total loss:  1.3446 | PDE Loss:  0.6724 | Function Loss:  0.2407\n",
      "Total loss:  1.3437 | PDE Loss:  0.6797 | Function Loss:  0.2376\n",
      "Total loss:  1.3428 | PDE Loss:  0.677 | Function Loss:  0.2372\n",
      "Total loss:  1.3413 | PDE Loss:  0.6885 | Function Loss:  0.2321\n",
      "Total loss:  1.3396 | PDE Loss:  0.68 | Function Loss:  0.2322\n",
      "Total loss:  1.3382 | PDE Loss:  0.6822 | Function Loss:  0.2298\n",
      "Total loss:  1.337 | PDE Loss:  0.6729 | Function Loss:  0.2309\n",
      "Total loss:  1.336 | PDE Loss:  0.6825 | Function Loss:  0.2269\n",
      "Total loss:  1.3351 | PDE Loss:  0.6576 | Function Loss:  0.2327\n",
      "Total loss:  1.3343 | PDE Loss:  0.6716 | Function Loss:  0.2279\n",
      "Total loss:  1.3334 | PDE Loss:  0.6791 | Function Loss:  0.2246\n",
      "Total loss:  1.3324 | PDE Loss:  0.6919 | Function Loss:  0.2196\n",
      "Total loss:  1.3314 | PDE Loss:  0.7071 | Function Loss:  0.2137\n",
      "Total loss:  1.3304 | PDE Loss:  0.6917 | Function Loss:  0.217\n",
      "Total loss:  1.3298 | PDE Loss:  0.6882 | Function Loss:  0.2173\n",
      "Total loss:  1.3287 | PDE Loss:  0.6982 | Function Loss:  0.2129\n",
      "Total loss:  1.3277 | PDE Loss:  0.6449 | Function Loss:  0.2267\n",
      "Total loss:  1.3269 | PDE Loss:  0.6744 | Function Loss:  0.2175\n",
      "Total loss:  1.3262 | PDE Loss:  0.6892 | Function Loss:  0.2124\n",
      "Total loss:  1.3253 | PDE Loss:  0.7034 | Function Loss:  0.2068\n",
      "Total loss:  1.3247 | PDE Loss:  0.7006 | Function Loss:  0.2068\n",
      "Total loss:  1.3243 | PDE Loss:  0.701 | Function Loss:  0.2063\n",
      "Total loss:  1.3241 | PDE Loss:  0.6949 | Function Loss:  0.2078\n",
      "Total loss:  1.3237 | PDE Loss:  0.694 | Function Loss:  0.2076\n",
      "Total loss:  1.3232 | PDE Loss:  0.6916 | Function Loss:  0.2077\n",
      "Total loss:  1.3227 | PDE Loss:  0.691 | Function Loss:  0.2071\n",
      "Total loss:  1.3219 | PDE Loss:  0.69 | Function Loss:  0.2065\n",
      "Total loss:  1.3209 | PDE Loss:  0.6892 | Function Loss:  0.2055\n",
      "Total loss:  1.3198 | PDE Loss:  0.6993 | Function Loss:  0.2008\n",
      "Total loss:  1.3194 | PDE Loss:  0.6501 | Function Loss:  0.2148\n",
      "Total loss:  1.3191 | PDE Loss:  0.6716 | Function Loss:  0.2083\n",
      "Total loss:  1.3181 | PDE Loss:  0.686 | Function Loss:  0.2027\n",
      "Total loss:  1.3174 | PDE Loss:  0.6919 | Function Loss:  0.2\n",
      "Total loss:  1.3166 | PDE Loss:  0.7087 | Function Loss:  0.1936\n",
      "Total loss:  1.3159 | PDE Loss:  0.7074 | Function Loss:  0.1931\n",
      "Total loss:  1.3153 | PDE Loss:  0.703 | Function Loss:  0.1938\n",
      "Total loss:  1.3146 | PDE Loss:  0.7214 | Function Loss:  0.1867\n",
      "Total loss:  1.3142 | PDE Loss:  0.7155 | Function Loss:  0.1882\n",
      "Total loss:  1.314 | PDE Loss:  0.7176 | Function Loss:  0.1872\n",
      "Total loss:  1.3139 | PDE Loss:  0.7155 | Function Loss:  0.1877\n",
      "Total loss:  1.3136 | PDE Loss:  0.7146 | Function Loss:  0.1877\n",
      "Total loss:  1.3133 | PDE Loss:  0.7092 | Function Loss:  0.189\n",
      "Total loss:  1.3129 | PDE Loss:  0.7068 | Function Loss:  0.1894\n",
      "Total loss:  1.3126 | PDE Loss:  0.7035 | Function Loss:  0.1899\n",
      "Total loss:  1.312 | PDE Loss:  0.7007 | Function Loss:  0.1901\n",
      "Total loss:  1.3111 | PDE Loss:  0.6952 | Function Loss:  0.1907\n",
      "Total loss:  1.3098 | PDE Loss:  0.6894 | Function Loss:  0.1908\n",
      "Total loss:  1.3085 | PDE Loss:  0.6833 | Function Loss:  0.1911\n",
      "Total loss:  1.3072 | PDE Loss:  0.6895 | Function Loss:  0.1873\n",
      "Total loss:  1.3058 | PDE Loss:  0.6798 | Function Loss:  0.1886\n",
      "Total loss:  1.304 | PDE Loss:  0.7228 | Function Loss:  0.1719\n",
      "Total loss:  1.303 | PDE Loss:  0.7106 | Function Loss:  0.1747\n",
      "Total loss:  1.3022 | PDE Loss:  0.7104 | Function Loss:  0.1737\n",
      "Total loss:  1.3008 | PDE Loss:  0.7266 | Function Loss:  0.1662\n",
      "Total loss:  1.2992 | PDE Loss:  0.717 | Function Loss:  0.1675\n",
      "Total loss:  1.2978 | PDE Loss:  0.7166 | Function Loss:  0.1657\n",
      "Total loss:  1.2966 | PDE Loss:  0.7608 | Function Loss:  0.1471\n",
      "Total loss:  1.2954 | PDE Loss:  0.733 | Function Loss:  0.1565\n",
      "Total loss:  1.2946 | PDE Loss:  0.7359 | Function Loss:  0.1542\n",
      "Total loss:  1.2939 | PDE Loss:  0.7301 | Function Loss:  0.1555\n",
      "Total loss:  1.2929 | PDE Loss:  0.7303 | Function Loss:  0.154\n",
      "Total loss:  1.2918 | PDE Loss:  0.7228 | Function Loss:  0.1553\n",
      "Total loss:  1.2904 | PDE Loss:  0.7261 | Function Loss:  0.1521\n",
      "Total loss:  1.2889 | PDE Loss:  0.7104 | Function Loss:  0.1558\n",
      "Total loss:  1.2878 | PDE Loss:  0.7225 | Function Loss:  0.1499\n",
      "Total loss:  1.2871 | PDE Loss:  0.7277 | Function Loss:  0.1469\n",
      "Total loss:  1.2865 | PDE Loss:  0.733 | Function Loss:  0.1441\n",
      "Total loss:  1.2858 | PDE Loss:  0.7357 | Function Loss:  0.1421\n",
      "Total loss:  1.2844 | PDE Loss:  0.7376 | Function Loss:  0.1394\n",
      "Total loss:  1.2828 | PDE Loss:  0.7549 | Function Loss:  0.13\n",
      "Total loss:  1.2821 | PDE Loss:  0.7276 | Function Loss:  0.1401\n",
      "Total loss:  1.2808 | PDE Loss:  0.7361 | Function Loss:  0.1349\n",
      "Total loss:  1.2797 | PDE Loss:  0.7486 | Function Loss:  0.1282\n",
      "Total loss:  1.2788 | PDE Loss:  0.7412 | Function Loss:  0.1301\n",
      "Total loss:  1.2781 | PDE Loss:  0.7488 | Function Loss:  0.1259\n",
      "Total loss:  1.2778 | PDE Loss:  0.7492 | Function Loss:  0.1252\n",
      "Total loss:  1.2772 | PDE Loss:  0.7448 | Function Loss:  0.1263\n",
      "Total loss:  1.2767 | PDE Loss:  0.7416 | Function Loss:  0.1269\n",
      "Total loss:  1.2764 | PDE Loss:  0.7375 | Function Loss:  0.1282\n",
      "Total loss:  1.2761 | PDE Loss:  0.7362 | Function Loss:  0.1283\n",
      "Total loss:  1.2758 | PDE Loss:  0.7318 | Function Loss:  0.1296\n",
      "Total loss:  1.2753 | PDE Loss:  0.7305 | Function Loss:  0.1295\n",
      "Total loss:  1.2746 | PDE Loss:  0.7255 | Function Loss:  0.1305\n",
      "Total loss:  1.2738 | PDE Loss:  0.7262 | Function Loss:  0.1291\n",
      "Total loss:  1.2727 | PDE Loss:  0.7221 | Function Loss:  0.1291\n",
      "Total loss:  1.2714 | PDE Loss:  0.7376 | Function Loss:  0.1211\n",
      "Total loss:  1.2704 | PDE Loss:  0.7319 | Function Loss:  0.1221\n",
      "Total loss:  1.2698 | PDE Loss:  0.7428 | Function Loss:  0.1166\n",
      "Total loss:  1.2692 | PDE Loss:  0.7549 | Function Loss:  0.1106\n",
      "Total loss:  1.2686 | PDE Loss:  0.7601 | Function Loss:  0.1074\n",
      "Total loss:  1.2683 | PDE Loss:  0.7653 | Function Loss:  0.1046\n",
      "Total loss:  1.2679 | PDE Loss:  0.7694 | Function Loss:  0.102\n",
      "Total loss:  1.2674 | PDE Loss:  0.7691 | Function Loss:  0.1015\n",
      "Total loss:  1.2664 | PDE Loss:  0.7721 | Function Loss:  0.0986\n",
      "Total loss:  1.2652 | PDE Loss:  0.7645 | Function Loss:  0.1004\n",
      "Total loss:  1.2645 | PDE Loss:  0.7625 | Function Loss:  0.1003\n",
      "Total loss:  1.2638 | PDE Loss:  0.7545 | Function Loss:  0.103\n",
      "Total loss:  1.2633 | PDE Loss:  0.7524 | Function Loss:  0.1031\n",
      "Total loss:  1.263 | PDE Loss:  0.7487 | Function Loss:  0.1043\n",
      "Total loss:  1.2627 | PDE Loss:  0.7504 | Function Loss:  0.1031\n",
      "Total loss:  1.2623 | PDE Loss:  0.749 | Function Loss:  0.1032\n",
      "Total loss:  1.2616 | PDE Loss:  0.7587 | Function Loss:  0.0978\n",
      "Total loss:  1.2608 | PDE Loss:  0.7566 | Function Loss:  0.0977\n",
      "Total loss:  1.2599 | PDE Loss:  0.7713 | Function Loss:  0.0895\n",
      "Total loss:  1.259 | PDE Loss:  0.773 | Function Loss:  0.0873\n",
      "Total loss:  1.2579 | PDE Loss:  0.7871 | Function Loss:  0.0786\n",
      "Total loss:  1.2568 | PDE Loss:  0.791 | Function Loss:  0.0749\n",
      "Total loss:  1.2559 | PDE Loss:  0.7952 | Function Loss:  0.0713\n",
      "Total loss:  1.2549 | PDE Loss:  0.8041 | Function Loss:  0.0651\n",
      "Total loss:  1.2541 | PDE Loss:  0.7904 | Function Loss:  0.0712\n",
      "Total loss:  1.2535 | PDE Loss:  0.7982 | Function Loss:  0.0661\n",
      "Total loss:  1.253 | PDE Loss:  0.7839 | Function Loss:  0.0729\n",
      "Total loss:  1.2525 | PDE Loss:  0.7939 | Function Loss:  0.0669\n",
      "Total loss:  1.2521 | PDE Loss:  0.7888 | Function Loss:  0.0689\n",
      "Total loss:  1.2515 | PDE Loss:  0.7843 | Function Loss:  0.0704\n",
      "Total loss:  1.2504 | PDE Loss:  0.7736 | Function Loss:  0.0742\n",
      "Total loss:  1.2488 | PDE Loss:  0.7604 | Function Loss:  0.0783\n",
      "Total loss:  1.2471 | PDE Loss:  0.7553 | Function Loss:  0.0782\n",
      "Total loss:  1.2453 | PDE Loss:  0.7504 | Function Loss:  0.0778\n",
      "Total loss:  1.2428 | PDE Loss:  0.763 | Function Loss:  0.0681\n",
      "Total loss:  1.2404 | PDE Loss:  0.7499 | Function Loss:  0.0708\n",
      "Total loss:  1.2386 | PDE Loss:  0.7801 | Function Loss:  0.0529\n",
      "Total loss:  1.2375 | PDE Loss:  0.7809 | Function Loss:  0.0508\n",
      "Total loss:  1.2369 | PDE Loss:  0.7743 | Function Loss:  0.0534\n",
      "Total loss:  1.2365 | PDE Loss:  0.7779 | Function Loss:  0.0508\n",
      "Total loss:  1.236 | PDE Loss:  0.7765 | Function Loss:  0.0508\n",
      "Total loss:  1.2352 | PDE Loss:  0.7698 | Function Loss:  0.0531\n",
      "Total loss:  1.2342 | PDE Loss:  0.7741 | Function Loss:  0.0494\n",
      "Total loss:  1.2323 | PDE Loss:  0.7707 | Function Loss:  0.0483\n",
      "Total loss:  1.2301 | PDE Loss:  0.7701 | Function Loss:  0.0452\n",
      "Total loss:  1.2273 | PDE Loss:  0.7678 | Function Loss:  0.042\n",
      "Total loss:  1.2227 | PDE Loss:  0.7733 | Function Loss:  0.0321\n",
      "Total loss:  1.218 | PDE Loss:  0.7534 | Function Loss:  0.0355\n",
      "Total loss:  1.2154 | PDE Loss:  0.7747 | Function Loss:  0.02\n",
      "Total loss:  1.2135 | PDE Loss:  0.7609 | Function Loss:  0.0246\n",
      "Total loss:  1.2116 | PDE Loss:  0.7623 | Function Loss:  0.021\n",
      "Total loss:  1.21 | PDE Loss:  0.7582 | Function Loss:  0.0207\n",
      "Total loss:  1.2088 | PDE Loss:  0.754 | Function Loss:  0.0211\n",
      "Total loss:  1.2078 | PDE Loss:  0.7619 | Function Loss:  0.0153\n",
      "Total loss:  1.2068 | PDE Loss:  0.7588 | Function Loss:  0.0154\n",
      "Total loss:  1.2051 | PDE Loss:  0.7666 | Function Loss:  0.0084\n",
      "Total loss:  1.2027 | PDE Loss:  0.7608 | Function Loss:  0.0079\n",
      "Total loss:  1.2009 | PDE Loss:  0.7727 | Function Loss:  -0.0019\n",
      "Total loss:  1.1993 | PDE Loss:  0.7664 | Function Loss:  -0.0006\n",
      "Total loss:  1.1979 | PDE Loss:  0.764 | Function Loss:  -0.0016\n",
      "Total loss:  1.1961 | PDE Loss:  0.7546 | Function Loss:  0.001\n",
      "Total loss:  1.1947 | PDE Loss:  0.7566 | Function Loss:  -0.0024\n",
      "Total loss:  1.1936 | PDE Loss:  0.743 | Function Loss:  0.0036\n",
      "Total loss:  1.1926 | PDE Loss:  0.746 | Function Loss:  0.0005\n",
      "Total loss:  1.192 | PDE Loss:  0.7379 | Function Loss:  0.0039\n",
      "Total loss:  1.1912 | PDE Loss:  0.734 | Function Loss:  0.0048\n",
      "Total loss:  1.1903 | PDE Loss:  0.7302 | Function Loss:  0.0055\n",
      "Total loss:  1.1886 | PDE Loss:  0.7328 | Function Loss:  0.0015\n",
      "Total loss:  1.1869 | PDE Loss:  0.72 | Function Loss:  0.0056\n",
      "Total loss:  1.1856 | PDE Loss:  0.7238 | Function Loss:  0.0016\n",
      "Total loss:  1.1838 | PDE Loss:  0.7244 | Function Loss:  -0.0014\n",
      "Total loss:  1.1814 | PDE Loss:  0.7282 | Function Loss:  -0.0071\n",
      "Total loss:  1.1789 | PDE Loss:  0.733 | Function Loss:  -0.0137\n",
      "Total loss:  1.1772 | PDE Loss:  0.7377 | Function Loss:  -0.019\n",
      "Total loss:  1.1754 | PDE Loss:  0.7446 | Function Loss:  -0.0258\n",
      "Total loss:  1.1739 | PDE Loss:  0.7369 | Function Loss:  -0.0237\n",
      "Total loss:  1.1729 | PDE Loss:  0.7457 | Function Loss:  -0.0305\n",
      "Total loss:  1.1721 | PDE Loss:  0.7403 | Function Loss:  -0.0286\n",
      "Total loss:  1.1713 | PDE Loss:  0.7305 | Function Loss:  -0.0242\n",
      "Total loss:  1.1705 | PDE Loss:  0.73 | Function Loss:  -0.0252\n",
      "Total loss:  1.1695 | PDE Loss:  0.7194 | Function Loss:  -0.0208\n",
      "Total loss:  1.1687 | PDE Loss:  0.7265 | Function Loss:  -0.026\n",
      "Total loss:  1.1681 | PDE Loss:  0.7249 | Function Loss:  -0.0259\n",
      "Total loss:  1.1675 | PDE Loss:  0.7212 | Function Loss:  -0.0249\n",
      "Total loss:  1.1664 | PDE Loss:  0.7238 | Function Loss:  -0.0281\n",
      "Total loss:  1.1651 | PDE Loss:  0.7176 | Function Loss:  -0.0266\n",
      "Total loss:  1.1638 | PDE Loss:  0.7183 | Function Loss:  -0.029\n",
      "Total loss:  1.1626 | PDE Loss:  0.7157 | Function Loss:  -0.0295\n",
      "Total loss:  1.1614 | PDE Loss:  0.7147 | Function Loss:  -0.0308\n",
      "Total loss:  1.1603 | PDE Loss:  0.7157 | Function Loss:  -0.033\n",
      "Total loss:  1.1592 | PDE Loss:  0.7119 | Function Loss:  -0.0326\n",
      "Total loss:  1.1579 | PDE Loss:  0.7123 | Function Loss:  -0.0349\n",
      "Total loss:  1.1559 | PDE Loss:  0.709 | Function Loss:  -0.0361\n",
      "Total loss:  1.1541 | PDE Loss:  0.7111 | Function Loss:  -0.0401\n",
      "Total loss:  1.152 | PDE Loss:  0.7082 | Function Loss:  -0.0418\n",
      "Total loss:  1.1503 | PDE Loss:  0.7068 | Function Loss:  -0.0437\n",
      "Total loss:  1.148 | PDE Loss:  0.6956 | Function Loss:  -0.0411\n",
      "Total loss:  1.1463 | PDE Loss:  0.7007 | Function Loss:  -0.0465\n",
      "Total loss:  1.1447 | PDE Loss:  0.6908 | Function Loss:  -0.0434\n",
      "Total loss:  1.1435 | PDE Loss:  0.6946 | Function Loss:  -0.0474\n",
      "Total loss:  1.1427 | PDE Loss:  0.7023 | Function Loss:  -0.053\n",
      "Total loss:  1.142 | PDE Loss:  0.6803 | Function Loss:  -0.0421\n",
      "Total loss:  1.1414 | PDE Loss:  0.6819 | Function Loss:  -0.0438\n",
      "Total loss:  1.1407 | PDE Loss:  0.6837 | Function Loss:  -0.0458\n",
      "Total loss:  1.1398 | PDE Loss:  0.6806 | Function Loss:  -0.0456\n",
      "Total loss:  1.1385 | PDE Loss:  0.6843 | Function Loss:  -0.0496\n",
      "Total loss:  1.1373 | PDE Loss:  0.6764 | Function Loss:  -0.0471\n",
      "Total loss:  1.1363 | PDE Loss:  0.6763 | Function Loss:  -0.0486\n",
      "Total loss:  1.135 | PDE Loss:  0.671 | Function Loss:  -0.0477\n",
      "Total loss:  1.1337 | PDE Loss:  0.6728 | Function Loss:  -0.0508\n",
      "Total loss:  1.1324 | PDE Loss:  0.6623 | Function Loss:  -0.0473\n",
      "Total loss:  1.1316 | PDE Loss:  0.6697 | Function Loss:  -0.0523\n",
      "Total loss:  1.1311 | PDE Loss:  0.6642 | Function Loss:  -0.0502\n",
      "Total loss:  1.1307 | PDE Loss:  0.664 | Function Loss:  -0.0508\n",
      "Total loss:  1.1302 | PDE Loss:  0.6613 | Function Loss:  -0.05\n",
      "Total loss:  1.1296 | PDE Loss:  0.6582 | Function Loss:  -0.0494\n",
      "Total loss:  1.1285 | PDE Loss:  0.6542 | Function Loss:  -0.049\n",
      "Total loss:  1.1271 | PDE Loss:  0.6393 | Function Loss:  -0.0438\n",
      "Total loss:  1.1257 | PDE Loss:  0.6356 | Function Loss:  -0.044\n",
      "Total loss:  1.1237 | PDE Loss:  0.636 | Function Loss:  -0.0472\n",
      "Total loss:  1.1219 | PDE Loss:  0.6355 | Function Loss:  -0.0497\n",
      "Total loss:  1.1206 | PDE Loss:  0.6094 | Function Loss:  -0.0395\n",
      "Total loss:  1.1193 | PDE Loss:  0.6314 | Function Loss:  -0.0515\n",
      "Total loss:  1.1187 | PDE Loss:  0.6332 | Function Loss:  -0.0533\n",
      "Total loss:  1.1179 | PDE Loss:  0.6307 | Function Loss:  -0.0532\n",
      "Total loss:  1.1172 | PDE Loss:  0.6353 | Function Loss:  -0.0565\n",
      "Total loss:  1.1167 | PDE Loss:  0.6348 | Function Loss:  -0.0569\n",
      "Total loss:  1.1162 | PDE Loss:  0.6343 | Function Loss:  -0.0576\n",
      "Total loss:  1.1153 | PDE Loss:  0.6307 | Function Loss:  -0.0571\n",
      "Total loss:  1.1145 | PDE Loss:  0.6287 | Function Loss:  -0.0573\n",
      "Total loss:  1.1139 | PDE Loss:  0.6226 | Function Loss:  -0.0552\n",
      "Total loss:  1.1135 | PDE Loss:  0.6235 | Function Loss:  -0.0563\n",
      "Total loss:  1.1131 | PDE Loss:  0.6211 | Function Loss:  -0.0557\n",
      "Total loss:  1.1128 | PDE Loss:  0.6183 | Function Loss:  -0.0549\n",
      "Total loss:  1.1124 | PDE Loss:  0.6203 | Function Loss:  -0.0563\n",
      "Total loss:  1.1122 | PDE Loss:  0.6174 | Function Loss:  -0.0553\n",
      "Total loss:  1.1119 | PDE Loss:  0.6199 | Function Loss:  -0.0569\n",
      "Total loss:  1.1114 | PDE Loss:  0.6168 | Function Loss:  -0.0561\n",
      "Total loss:  1.1107 | PDE Loss:  0.6216 | Function Loss:  -0.0595\n",
      "Total loss:  1.1099 | PDE Loss:  0.6165 | Function Loss:  -0.0583\n",
      "Total loss:  1.1093 | PDE Loss:  0.6124 | Function Loss:  -0.0572\n",
      "Total loss:  1.109 | PDE Loss:  0.6092 | Function Loss:  -0.0562\n",
      "Total loss:  1.1087 | PDE Loss:  0.6061 | Function Loss:  -0.0551\n",
      "Total loss:  1.1086 | PDE Loss:  0.6026 | Function Loss:  -0.0538\n",
      "Total loss:  1.1084 | PDE Loss:  0.6014 | Function Loss:  -0.0534\n",
      "Total loss:  1.1083 | PDE Loss:  0.5989 | Function Loss:  -0.0525\n",
      "Total loss:  1.1081 | PDE Loss:  0.5993 | Function Loss:  -0.053\n",
      "Total loss:  1.1077 | PDE Loss:  0.5923 | Function Loss:  -0.0504\n",
      "Total loss:  1.1073 | PDE Loss:  0.5942 | Function Loss:  -0.0519\n",
      "Total loss:  1.1068 | PDE Loss:  0.5903 | Function Loss:  -0.0509\n",
      "Total loss:  1.1062 | PDE Loss:  0.5904 | Function Loss:  -0.0518\n",
      "Total loss:  1.1056 | PDE Loss:  0.5877 | Function Loss:  -0.0515\n",
      "Total loss:  1.105 | PDE Loss:  0.591 | Function Loss:  -0.0538\n",
      "Total loss:  1.1044 | PDE Loss:  0.5868 | Function Loss:  -0.0527\n",
      "Total loss:  1.1041 | PDE Loss:  0.5906 | Function Loss:  -0.0549\n",
      "Total loss:  1.1038 | PDE Loss:  0.5887 | Function Loss:  -0.0545\n",
      "Total loss:  1.1035 | PDE Loss:  0.5908 | Function Loss:  -0.0558\n",
      "Total loss:  1.1033 | PDE Loss:  0.5903 | Function Loss:  -0.0559\n",
      "Total loss:  1.1031 | PDE Loss:  0.5915 | Function Loss:  -0.0568\n",
      "Total loss:  1.1027 | PDE Loss:  0.5892 | Function Loss:  -0.0563\n",
      "Total loss:  1.1024 | PDE Loss:  0.5944 | Function Loss:  -0.059\n",
      "Total loss:  1.1021 | PDE Loss:  0.5918 | Function Loss:  -0.0583\n",
      "Total loss:  1.1019 | PDE Loss:  0.5924 | Function Loss:  -0.0589\n",
      "Total loss:  1.1015 | PDE Loss:  0.5908 | Function Loss:  -0.0587\n",
      "Total loss:  1.101 | PDE Loss:  0.5943 | Function Loss:  -0.061\n",
      "Total loss:  1.1006 | PDE Loss:  0.5911 | Function Loss:  -0.0601\n",
      "Total loss:  1.1003 | PDE Loss:  0.594 | Function Loss:  -0.0619\n",
      "Total loss:  1.1 | PDE Loss:  0.591 | Function Loss:  -0.061\n",
      "Total loss:  1.0999 | PDE Loss:  0.5911 | Function Loss:  -0.0612\n",
      "Total loss:  1.0997 | PDE Loss:  0.5908 | Function Loss:  -0.0614\n",
      "Total loss:  1.0993 | PDE Loss:  0.5917 | Function Loss:  -0.0623\n",
      "Total loss:  1.099 | PDE Loss:  0.5916 | Function Loss:  -0.0628\n",
      "Total loss:  1.0985 | PDE Loss:  0.5943 | Function Loss:  -0.0646\n",
      "Total loss:  1.0982 | PDE Loss:  0.5947 | Function Loss:  -0.0652\n",
      "Total loss:  1.0979 | PDE Loss:  0.5953 | Function Loss:  -0.066\n",
      "Total loss:  1.0976 | PDE Loss:  0.594 | Function Loss:  -0.0658\n",
      "Total loss:  1.0973 | PDE Loss:  0.5981 | Function Loss:  -0.0682\n",
      "Total loss:  1.097 | PDE Loss:  0.599 | Function Loss:  -0.0691\n",
      "Total loss:  1.0965 | PDE Loss:  0.6002 | Function Loss:  -0.0703\n",
      "Total loss:  1.0961 | PDE Loss:  0.6042 | Function Loss:  -0.0728\n",
      "Total loss:  1.0959 | PDE Loss:  0.6035 | Function Loss:  -0.0728\n",
      "Total loss:  1.0957 | PDE Loss:  0.6046 | Function Loss:  -0.0735\n",
      "Total loss:  1.0956 | PDE Loss:  0.6033 | Function Loss:  -0.0732\n",
      "Total loss:  1.0954 | PDE Loss:  0.6034 | Function Loss:  -0.0734\n",
      "Total loss:  1.0952 | PDE Loss:  0.6026 | Function Loss:  -0.0733\n",
      "Total loss:  1.0949 | PDE Loss:  0.6025 | Function Loss:  -0.0737\n",
      "Total loss:  1.0945 | PDE Loss:  0.6024 | Function Loss:  -0.0742\n",
      "Total loss:  1.094 | PDE Loss:  0.6037 | Function Loss:  -0.0756\n",
      "Total loss:  1.0934 | PDE Loss:  0.6052 | Function Loss:  -0.0772\n",
      "Total loss:  1.093 | PDE Loss:  0.6016 | Function Loss:  -0.0761\n",
      "Total loss:  1.0925 | PDE Loss:  0.6066 | Function Loss:  -0.0793\n",
      "Total loss:  1.092 | PDE Loss:  0.6018 | Function Loss:  -0.0776\n",
      "Total loss:  1.0917 | PDE Loss:  0.6035 | Function Loss:  -0.0789\n",
      "Total loss:  1.0915 | PDE Loss:  0.6079 | Function Loss:  -0.0814\n",
      "Total loss:  1.0913 | PDE Loss:  0.5976 | Function Loss:  -0.0768\n",
      "Total loss:  1.0912 | PDE Loss:  0.6027 | Function Loss:  -0.0793\n",
      "Total loss:  1.0911 | PDE Loss:  0.6034 | Function Loss:  -0.0798\n",
      "Total loss:  1.091 | PDE Loss:  0.6039 | Function Loss:  -0.0802\n",
      "Total loss:  1.0908 | PDE Loss:  0.6051 | Function Loss:  -0.0811\n",
      "Total loss:  1.0905 | PDE Loss:  0.6044 | Function Loss:  -0.0812\n",
      "Total loss:  1.0901 | PDE Loss:  0.6071 | Function Loss:  -0.083\n",
      "Total loss:  1.0898 | PDE Loss:  0.6041 | Function Loss:  -0.0821\n",
      "Total loss:  1.0895 | PDE Loss:  0.6074 | Function Loss:  -0.0842\n",
      "Total loss:  1.0893 | PDE Loss:  0.6035 | Function Loss:  -0.0825\n",
      "Total loss:  1.0892 | PDE Loss:  0.6057 | Function Loss:  -0.0838\n",
      "Total loss:  1.0891 | PDE Loss:  0.6022 | Function Loss:  -0.0822\n",
      "Total loss:  1.089 | PDE Loss:  0.6028 | Function Loss:  -0.0826\n",
      "Total loss:  1.089 | PDE Loss:  0.6023 | Function Loss:  -0.0824\n",
      "Total loss:  1.0888 | PDE Loss:  0.6013 | Function Loss:  -0.0822\n",
      "Total loss:  1.0885 | PDE Loss:  0.6006 | Function Loss:  -0.0823\n",
      "Total loss:  1.0882 | PDE Loss:  0.6011 | Function Loss:  -0.083\n",
      "Total loss:  1.0879 | PDE Loss:  0.6014 | Function Loss:  -0.0836\n",
      "Total loss:  1.0877 | PDE Loss:  0.5994 | Function Loss:  -0.0829\n",
      "Total loss:  1.0874 | PDE Loss:  0.6026 | Function Loss:  -0.0849\n",
      "Total loss:  1.0873 | PDE Loss:  0.6003 | Function Loss:  -0.084\n",
      "Total loss:  1.0871 | PDE Loss:  0.602 | Function Loss:  -0.085\n",
      "Total loss:  1.087 | PDE Loss:  0.6021 | Function Loss:  -0.0852\n",
      "Total loss:  1.0869 | PDE Loss:  0.6021 | Function Loss:  -0.0854\n",
      "Total loss:  1.0867 | PDE Loss:  0.6004 | Function Loss:  -0.0849\n",
      "Total loss:  1.0865 | PDE Loss:  0.6008 | Function Loss:  -0.0854\n",
      "Total loss:  1.0863 | PDE Loss:  0.5971 | Function Loss:  -0.0839\n",
      "Total loss:  1.0861 | PDE Loss:  0.5949 | Function Loss:  -0.083\n",
      "Total loss:  1.086 | PDE Loss:  0.5972 | Function Loss:  -0.0844\n",
      "Total loss:  1.0858 | PDE Loss:  0.5933 | Function Loss:  -0.0828\n",
      "Total loss:  1.0857 | PDE Loss:  0.5939 | Function Loss:  -0.0833\n",
      "Total loss:  1.0855 | PDE Loss:  0.592 | Function Loss:  -0.0826\n",
      "Total loss:  1.0853 | PDE Loss:  0.5907 | Function Loss:  -0.0823\n",
      "Total loss:  1.0851 | PDE Loss:  0.5908 | Function Loss:  -0.0827\n",
      "Total loss:  1.0849 | PDE Loss:  0.5871 | Function Loss:  -0.0812\n",
      "Total loss:  1.0847 | PDE Loss:  0.5897 | Function Loss:  -0.0827\n",
      "Total loss:  1.0845 | PDE Loss:  0.5884 | Function Loss:  -0.0824\n",
      "Total loss:  1.0843 | PDE Loss:  0.5897 | Function Loss:  -0.0834\n",
      "Total loss:  1.084 | PDE Loss:  0.5905 | Function Loss:  -0.0841\n",
      "Total loss:  1.0838 | PDE Loss:  0.5883 | Function Loss:  -0.0835\n",
      "Total loss:  1.0836 | PDE Loss:  0.5923 | Function Loss:  -0.0855\n",
      "Total loss:  1.0835 | PDE Loss:  0.5899 | Function Loss:  -0.0846\n",
      "Total loss:  1.0834 | PDE Loss:  0.5913 | Function Loss:  -0.0854\n",
      "Total loss:  1.0833 | PDE Loss:  0.5897 | Function Loss:  -0.0848\n",
      "Total loss:  1.0833 | PDE Loss:  0.589 | Function Loss:  -0.0845\n",
      "Total loss:  1.0832 | PDE Loss:  0.5889 | Function Loss:  -0.0846\n",
      "Total loss:  1.0831 | PDE Loss:  0.5864 | Function Loss:  -0.0835\n",
      "Total loss:  1.0829 | PDE Loss:  0.5879 | Function Loss:  -0.0844\n",
      "Total loss:  1.0828 | PDE Loss:  0.5849 | Function Loss:  -0.0833\n",
      "Total loss:  1.0827 | PDE Loss:  0.5844 | Function Loss:  -0.0832\n",
      "Total loss:  1.0825 | PDE Loss:  0.5835 | Function Loss:  -0.0831\n",
      "Total loss:  1.0823 | PDE Loss:  0.5832 | Function Loss:  -0.0832\n",
      "Total loss:  1.0821 | PDE Loss:  0.5841 | Function Loss:  -0.0839\n",
      "Total loss:  1.082 | PDE Loss:  0.5848 | Function Loss:  -0.0845\n",
      "Total loss:  1.0818 | PDE Loss:  0.5872 | Function Loss:  -0.0858\n",
      "Total loss:  1.0817 | PDE Loss:  0.5887 | Function Loss:  -0.0867\n",
      "Total loss:  1.0815 | PDE Loss:  0.5895 | Function Loss:  -0.0873\n",
      "Total loss:  1.0813 | PDE Loss:  0.5926 | Function Loss:  -0.0891\n",
      "Total loss:  1.0811 | PDE Loss:  0.588 | Function Loss:  -0.0872\n",
      "Total loss:  1.081 | PDE Loss:  0.5921 | Function Loss:  -0.0893\n",
      "Total loss:  1.0809 | PDE Loss:  0.5901 | Function Loss:  -0.0885\n",
      "Total loss:  1.0808 | PDE Loss:  0.5895 | Function Loss:  -0.0884\n",
      "Total loss:  1.0807 | PDE Loss:  0.5799 | Function Loss:  -0.0841\n",
      "Total loss:  1.0806 | PDE Loss:  0.5807 | Function Loss:  -0.0846\n",
      "Total loss:  1.0804 | PDE Loss:  0.5811 | Function Loss:  -0.085\n",
      "Total loss:  1.0802 | PDE Loss:  0.5789 | Function Loss:  -0.0843\n",
      "Total loss:  1.08 | PDE Loss:  0.5841 | Function Loss:  -0.087\n",
      "Total loss:  1.0797 | PDE Loss:  0.5792 | Function Loss:  -0.0852\n",
      "Total loss:  1.0794 | PDE Loss:  0.5781 | Function Loss:  -0.0851\n",
      "Total loss:  1.079 | PDE Loss:  0.5783 | Function Loss:  -0.0857\n",
      "Total loss:  1.0787 | PDE Loss:  0.5774 | Function Loss:  -0.0858\n",
      "Total loss:  1.0784 | PDE Loss:  0.5881 | Function Loss:  -0.0913\n",
      "Total loss:  1.0782 | PDE Loss:  0.5859 | Function Loss:  -0.0905\n",
      "Total loss:  1.0781 | PDE Loss:  0.5867 | Function Loss:  -0.091\n",
      "Total loss:  1.078 | PDE Loss:  0.5862 | Function Loss:  -0.091\n",
      "Total loss:  1.0779 | PDE Loss:  0.5888 | Function Loss:  -0.0924\n",
      "Total loss:  1.0778 | PDE Loss:  0.5875 | Function Loss:  -0.0919\n",
      "Total loss:  1.0777 | PDE Loss:  0.588 | Function Loss:  -0.0923\n",
      "Total loss:  1.0776 | PDE Loss:  0.5879 | Function Loss:  -0.0924\n",
      "Total loss:  1.0774 | PDE Loss:  0.5868 | Function Loss:  -0.0921\n",
      "Total loss:  1.0773 | PDE Loss:  0.5865 | Function Loss:  -0.0921\n",
      "Total loss:  1.0772 | PDE Loss:  0.5853 | Function Loss:  -0.0917\n",
      "Total loss:  1.0771 | PDE Loss:  0.583 | Function Loss:  -0.0907\n",
      "Total loss:  1.0771 | PDE Loss:  0.583 | Function Loss:  -0.0908\n",
      "Total loss:  1.077 | PDE Loss:  0.5813 | Function Loss:  -0.09\n",
      "Total loss:  1.077 | PDE Loss:  0.5811 | Function Loss:  -0.0901\n",
      "Total loss:  1.0769 | PDE Loss:  0.5799 | Function Loss:  -0.0896\n",
      "Total loss:  1.0768 | PDE Loss:  0.5796 | Function Loss:  -0.0897\n",
      "Total loss:  1.0766 | PDE Loss:  0.5769 | Function Loss:  -0.0887\n",
      "Total loss:  1.0764 | PDE Loss:  0.578 | Function Loss:  -0.0894\n",
      "Total loss:  1.0762 | PDE Loss:  0.5771 | Function Loss:  -0.0892\n",
      "Total loss:  1.076 | PDE Loss:  0.5788 | Function Loss:  -0.0905\n",
      "Total loss:  1.0757 | PDE Loss:  0.5793 | Function Loss:  -0.091\n",
      "Total loss:  1.0755 | PDE Loss:  0.5841 | Function Loss:  -0.0936\n",
      "Total loss:  1.0753 | PDE Loss:  0.5856 | Function Loss:  -0.0946\n",
      "Total loss:  1.0751 | PDE Loss:  0.5895 | Function Loss:  -0.0968\n",
      "Total loss:  1.0749 | PDE Loss:  0.5869 | Function Loss:  -0.0959\n",
      "Total loss:  1.0747 | PDE Loss:  0.5894 | Function Loss:  -0.0973\n",
      "Total loss:  1.0746 | PDE Loss:  0.5882 | Function Loss:  -0.097\n",
      "Total loss:  1.0744 | PDE Loss:  0.5872 | Function Loss:  -0.0967\n",
      "Total loss:  1.0743 | PDE Loss:  0.587 | Function Loss:  -0.0968\n",
      "Total loss:  1.0741 | PDE Loss:  0.5858 | Function Loss:  -0.0965\n",
      "Total loss:  1.074 | PDE Loss:  0.5856 | Function Loss:  -0.0966\n",
      "Total loss:  1.0739 | PDE Loss:  0.5839 | Function Loss:  -0.0959\n",
      "Total loss:  1.0739 | PDE Loss:  0.5913 | Function Loss:  -0.0995\n",
      "Total loss:  1.0738 | PDE Loss:  0.5869 | Function Loss:  -0.0975\n",
      "Total loss:  1.0737 | PDE Loss:  0.5834 | Function Loss:  -0.096\n",
      "Total loss:  1.0736 | PDE Loss:  0.5842 | Function Loss:  -0.0965\n",
      "Total loss:  1.0735 | PDE Loss:  0.58 | Function Loss:  -0.0947\n",
      "Total loss:  1.0734 | PDE Loss:  0.5805 | Function Loss:  -0.095\n",
      "Total loss:  1.0733 | PDE Loss:  0.5798 | Function Loss:  -0.0948\n",
      "Total loss:  1.0732 | PDE Loss:  0.5797 | Function Loss:  -0.0949\n",
      "Total loss:  1.0731 | PDE Loss:  0.581 | Function Loss:  -0.0957\n",
      "Total loss:  1.0729 | PDE Loss:  0.5792 | Function Loss:  -0.095\n",
      "Total loss:  1.0728 | PDE Loss:  0.5823 | Function Loss:  -0.0967\n",
      "Total loss:  1.0727 | PDE Loss:  0.5813 | Function Loss:  -0.0964\n",
      "Total loss:  1.0726 | PDE Loss:  0.5824 | Function Loss:  -0.0972\n",
      "Total loss:  1.0724 | PDE Loss:  0.5816 | Function Loss:  -0.097\n",
      "Total loss:  1.0723 | PDE Loss:  0.5802 | Function Loss:  -0.0964\n",
      "Total loss:  1.0722 | PDE Loss:  0.5811 | Function Loss:  -0.0971\n",
      "Total loss:  1.0721 | PDE Loss:  0.5791 | Function Loss:  -0.0963\n",
      "Total loss:  1.072 | PDE Loss:  0.5789 | Function Loss:  -0.0963\n",
      "Total loss:  1.0719 | PDE Loss:  0.5763 | Function Loss:  -0.0953\n",
      "Total loss:  1.0717 | PDE Loss:  0.5765 | Function Loss:  -0.0956\n",
      "Total loss:  1.0715 | PDE Loss:  0.575 | Function Loss:  -0.0952\n",
      "Total loss:  1.0713 | PDE Loss:  0.5759 | Function Loss:  -0.0959\n",
      "Total loss:  1.0711 | PDE Loss:  0.5762 | Function Loss:  -0.0963\n",
      "Total loss:  1.0709 | PDE Loss:  0.577 | Function Loss:  -0.097\n",
      "Total loss:  1.0707 | PDE Loss:  0.5817 | Function Loss:  -0.0996\n",
      "Total loss:  1.0705 | PDE Loss:  0.5814 | Function Loss:  -0.0997\n",
      "Total loss:  1.0703 | PDE Loss:  0.5824 | Function Loss:  -0.1004\n",
      "Total loss:  1.0701 | PDE Loss:  0.585 | Function Loss:  -0.102\n",
      "Total loss:  1.0699 | PDE Loss:  0.5833 | Function Loss:  -0.1016\n",
      "Total loss:  1.0698 | PDE Loss:  0.5864 | Function Loss:  -0.1033\n",
      "Total loss:  1.0697 | PDE Loss:  0.5864 | Function Loss:  -0.1034\n",
      "Total loss:  1.0696 | PDE Loss:  0.5839 | Function Loss:  -0.1023\n",
      "Total loss:  1.0695 | PDE Loss:  0.5855 | Function Loss:  -0.1032\n",
      "Total loss:  1.0695 | PDE Loss:  0.5837 | Function Loss:  -0.1024\n",
      "Total loss:  1.0694 | PDE Loss:  0.5838 | Function Loss:  -0.1025\n",
      "Total loss:  1.0693 | PDE Loss:  0.5841 | Function Loss:  -0.1028\n",
      "Total loss:  1.0692 | PDE Loss:  0.5843 | Function Loss:  -0.1031\n",
      "Total loss:  1.069 | PDE Loss:  0.5851 | Function Loss:  -0.1037\n",
      "Total loss:  1.0688 | PDE Loss:  0.5851 | Function Loss:  -0.104\n",
      "Total loss:  1.0686 | PDE Loss:  0.5858 | Function Loss:  -0.1047\n",
      "Total loss:  1.0683 | PDE Loss:  0.5854 | Function Loss:  -0.1049\n",
      "Total loss:  1.0678 | PDE Loss:  0.5812 | Function Loss:  -0.1036\n",
      "Total loss:  1.0673 | PDE Loss:  0.5815 | Function Loss:  -0.1044\n",
      "Total loss:  1.0669 | PDE Loss:  0.5731 | Function Loss:  -0.101\n",
      "Total loss:  1.0667 | PDE Loss:  0.5729 | Function Loss:  -0.1014\n",
      "Total loss:  1.0665 | PDE Loss:  0.5732 | Function Loss:  -0.1017\n",
      "Total loss:  1.0663 | PDE Loss:  0.5704 | Function Loss:  -0.1007\n",
      "Total loss:  1.0661 | PDE Loss:  0.5742 | Function Loss:  -0.1029\n",
      "Total loss:  1.0657 | PDE Loss:  0.572 | Function Loss:  -0.1023\n",
      "Total loss:  1.0655 | PDE Loss:  0.5822 | Function Loss:  -0.1075\n",
      "Total loss:  1.0652 | PDE Loss:  0.5812 | Function Loss:  -0.1075\n",
      "Total loss:  1.0648 | PDE Loss:  0.5767 | Function Loss:  -0.1059\n",
      "Total loss:  1.0645 | PDE Loss:  0.5766 | Function Loss:  -0.1063\n",
      "Total loss:  1.0642 | PDE Loss:  0.574 | Function Loss:  -0.1055\n",
      "Total loss:  1.064 | PDE Loss:  0.5762 | Function Loss:  -0.1069\n",
      "Total loss:  1.0638 | PDE Loss:  0.5757 | Function Loss:  -0.1069\n",
      "Total loss:  1.0637 | PDE Loss:  0.5671 | Function Loss:  -0.1029\n",
      "Total loss:  1.0636 | PDE Loss:  0.5698 | Function Loss:  -0.1043\n",
      "Total loss:  1.0636 | PDE Loss:  0.5688 | Function Loss:  -0.1039\n",
      "Total loss:  1.0635 | PDE Loss:  0.57 | Function Loss:  -0.1046\n",
      "Total loss:  1.0634 | PDE Loss:  0.5689 | Function Loss:  -0.1043\n",
      "Total loss:  1.0633 | PDE Loss:  0.5673 | Function Loss:  -0.1037\n",
      "Total loss:  1.0631 | PDE Loss:  0.5698 | Function Loss:  -0.1051\n",
      "Total loss:  1.0629 | PDE Loss:  0.5698 | Function Loss:  -0.1054\n",
      "Total loss:  1.0627 | PDE Loss:  0.5688 | Function Loss:  -0.1052\n",
      "Total loss:  1.0625 | PDE Loss:  0.5691 | Function Loss:  -0.1057\n",
      "Total loss:  1.0623 | PDE Loss:  0.571 | Function Loss:  -0.1069\n",
      "Total loss:  1.0621 | PDE Loss:  0.5708 | Function Loss:  -0.1071\n",
      "Total loss:  1.0619 | PDE Loss:  0.5715 | Function Loss:  -0.1077\n",
      "Total loss:  1.0617 | PDE Loss:  0.571 | Function Loss:  -0.1078\n",
      "Total loss:  1.0614 | PDE Loss:  0.5753 | Function Loss:  -0.1102\n",
      "Total loss:  1.0612 | PDE Loss:  0.5688 | Function Loss:  -0.1075\n",
      "Total loss:  1.061 | PDE Loss:  0.5711 | Function Loss:  -0.1088\n",
      "Total loss:  1.0608 | PDE Loss:  0.5702 | Function Loss:  -0.1087\n",
      "Total loss:  1.0606 | PDE Loss:  0.5661 | Function Loss:  -0.107\n",
      "Total loss:  1.0605 | PDE Loss:  0.5671 | Function Loss:  -0.1078\n",
      "Total loss:  1.0603 | PDE Loss:  0.5641 | Function Loss:  -0.1065\n",
      "Total loss:  1.0602 | PDE Loss:  0.5641 | Function Loss:  -0.1067\n",
      "Total loss:  1.06 | PDE Loss:  0.565 | Function Loss:  -0.1074\n",
      "Total loss:  1.0598 | PDE Loss:  0.5661 | Function Loss:  -0.1083\n",
      "Total loss:  1.0595 | PDE Loss:  0.5631 | Function Loss:  -0.1073\n",
      "Total loss:  1.0593 | PDE Loss:  0.5702 | Function Loss:  -0.111\n",
      "Total loss:  1.0592 | PDE Loss:  0.5681 | Function Loss:  -0.1101\n",
      "Total loss:  1.059 | PDE Loss:  0.5657 | Function Loss:  -0.1092\n",
      "Total loss:  1.0588 | PDE Loss:  0.564 | Function Loss:  -0.1087\n",
      "Total loss:  1.0585 | PDE Loss:  0.561 | Function Loss:  -0.1077\n",
      "Total loss:  1.0581 | PDE Loss:  0.5594 | Function Loss:  -0.1076\n",
      "Total loss:  1.0575 | PDE Loss:  0.5538 | Function Loss:  -0.1059\n",
      "Total loss:  1.057 | PDE Loss:  0.5548 | Function Loss:  -0.1071\n",
      "Total loss:  1.0566 | PDE Loss:  0.55 | Function Loss:  -0.1055\n",
      "Total loss:  1.0562 | PDE Loss:  0.5542 | Function Loss:  -0.108\n",
      "Total loss:  1.0559 | PDE Loss:  0.5516 | Function Loss:  -0.1072\n",
      "Total loss:  1.0556 | PDE Loss:  0.5523 | Function Loss:  -0.1079\n",
      "Total loss:  1.0554 | PDE Loss:  0.5562 | Function Loss:  -0.1101\n",
      "Total loss:  1.0551 | PDE Loss:  0.5539 | Function Loss:  -0.1095\n",
      "Total loss:  1.0546 | PDE Loss:  0.5562 | Function Loss:  -0.1112\n",
      "Total loss:  1.0544 | PDE Loss:  0.5501 | Function Loss:  -0.1088\n",
      "Total loss:  1.0539 | PDE Loss:  0.553 | Function Loss:  -0.1107\n",
      "Total loss:  1.0537 | PDE Loss:  0.5526 | Function Loss:  -0.1109\n",
      "Total loss:  1.0535 | PDE Loss:  0.5494 | Function Loss:  -0.1097\n",
      "Total loss:  1.0534 | PDE Loss:  0.5518 | Function Loss:  -0.111\n",
      "Total loss:  1.0532 | PDE Loss:  0.5508 | Function Loss:  -0.1108\n",
      "Total loss:  1.0531 | PDE Loss:  0.5532 | Function Loss:  -0.112\n",
      "Total loss:  1.0531 | PDE Loss:  0.555 | Function Loss:  -0.1129\n",
      "Total loss:  1.053 | PDE Loss:  0.5546 | Function Loss:  -0.1128\n",
      "Total loss:  1.0529 | PDE Loss:  0.5547 | Function Loss:  -0.113\n",
      "Total loss:  1.0529 | PDE Loss:  0.5547 | Function Loss:  -0.1131\n",
      "Total loss:  1.0528 | PDE Loss:  0.553 | Function Loss:  -0.1124\n",
      "Total loss:  1.0527 | PDE Loss:  0.5534 | Function Loss:  -0.1127\n",
      "Total loss:  1.0526 | PDE Loss:  0.5507 | Function Loss:  -0.1117\n",
      "Total loss:  1.0525 | PDE Loss:  0.5533 | Function Loss:  -0.113\n",
      "Total loss:  1.0524 | PDE Loss:  0.5528 | Function Loss:  -0.1129\n",
      "Total loss:  1.0523 | PDE Loss:  0.5517 | Function Loss:  -0.1125\n",
      "Total loss:  1.0523 | PDE Loss:  0.5528 | Function Loss:  -0.1131\n",
      "Total loss:  1.0522 | PDE Loss:  0.5515 | Function Loss:  -0.1126\n",
      "Total loss:  1.0521 | PDE Loss:  0.5515 | Function Loss:  -0.1127\n",
      "Total loss:  1.052 | PDE Loss:  0.5515 | Function Loss:  -0.1129\n",
      "Total loss:  1.0519 | PDE Loss:  0.5507 | Function Loss:  -0.1127\n",
      "Total loss:  1.0517 | PDE Loss:  0.5477 | Function Loss:  -0.1115\n",
      "Total loss:  1.0516 | PDE Loss:  0.5488 | Function Loss:  -0.1122\n",
      "Total loss:  1.0515 | PDE Loss:  0.5482 | Function Loss:  -0.1121\n",
      "Total loss:  1.0513 | PDE Loss:  0.5477 | Function Loss:  -0.1121\n",
      "Total loss:  1.0513 | PDE Loss:  0.5513 | Function Loss:  -0.1139\n",
      "Total loss:  1.0511 | PDE Loss:  0.549 | Function Loss:  -0.113\n",
      "Total loss:  1.051 | PDE Loss:  0.5473 | Function Loss:  -0.1124\n",
      "Total loss:  1.0509 | PDE Loss:  0.5484 | Function Loss:  -0.1131\n",
      "Total loss:  1.0507 | PDE Loss:  0.5447 | Function Loss:  -0.1116\n",
      "Total loss:  1.0506 | PDE Loss:  0.5464 | Function Loss:  -0.1125\n",
      "Total loss:  1.0505 | PDE Loss:  0.5457 | Function Loss:  -0.1123\n",
      "Total loss:  1.0504 | PDE Loss:  0.5461 | Function Loss:  -0.1127\n",
      "Total loss:  1.0503 | PDE Loss:  0.5465 | Function Loss:  -0.113\n",
      "Total loss:  1.0502 | PDE Loss:  0.5472 | Function Loss:  -0.1135\n",
      "Total loss:  1.0501 | PDE Loss:  0.5481 | Function Loss:  -0.1141\n",
      "Total loss:  1.0499 | PDE Loss:  0.5485 | Function Loss:  -0.1145\n",
      "Total loss:  1.0498 | PDE Loss:  0.5493 | Function Loss:  -0.115\n",
      "Total loss:  1.0496 | PDE Loss:  0.5491 | Function Loss:  -0.1153\n",
      "Total loss:  1.0494 | PDE Loss:  0.5477 | Function Loss:  -0.115\n",
      "Total loss:  1.0491 | PDE Loss:  0.5522 | Function Loss:  -0.1174\n",
      "Total loss:  1.0489 | PDE Loss:  0.5455 | Function Loss:  -0.1147\n",
      "Total loss:  1.0486 | PDE Loss:  0.5455 | Function Loss:  -0.115\n",
      "Total loss:  1.0483 | PDE Loss:  0.5379 | Function Loss:  -0.112\n",
      "Total loss:  1.0481 | PDE Loss:  0.5366 | Function Loss:  -0.1118\n",
      "Total loss:  1.0479 | PDE Loss:  0.5361 | Function Loss:  -0.1118\n",
      "Total loss:  1.0478 | PDE Loss:  0.5359 | Function Loss:  -0.112\n",
      "Total loss:  1.0475 | PDE Loss:  0.5364 | Function Loss:  -0.1125\n",
      "Total loss:  1.0473 | PDE Loss:  0.5362 | Function Loss:  -0.1127\n",
      "Total loss:  1.047 | PDE Loss:  0.5359 | Function Loss:  -0.113\n",
      "Total loss:  1.0467 | PDE Loss:  0.534 | Function Loss:  -0.1126\n",
      "Total loss:  1.0464 | PDE Loss:  0.5351 | Function Loss:  -0.1136\n",
      "Total loss:  1.0461 | PDE Loss:  0.5293 | Function Loss:  -0.1114\n",
      "Total loss:  1.0459 | PDE Loss:  0.5313 | Function Loss:  -0.1125\n",
      "Total loss:  1.0458 | PDE Loss:  0.5312 | Function Loss:  -0.1127\n",
      "Total loss:  1.0457 | PDE Loss:  0.5261 | Function Loss:  -0.1106\n",
      "Total loss:  1.0456 | PDE Loss:  0.5267 | Function Loss:  -0.111\n",
      "Total loss:  1.0456 | PDE Loss:  0.527 | Function Loss:  -0.1112\n",
      "Total loss:  1.0455 | PDE Loss:  0.5289 | Function Loss:  -0.1122\n",
      "Total loss:  1.0453 | PDE Loss:  0.5282 | Function Loss:  -0.1121\n",
      "Total loss:  1.0452 | PDE Loss:  0.53 | Function Loss:  -0.113\n",
      "Total loss:  1.045 | PDE Loss:  0.5293 | Function Loss:  -0.113\n",
      "Total loss:  1.0449 | PDE Loss:  0.5298 | Function Loss:  -0.1134\n",
      "Total loss:  1.0447 | PDE Loss:  0.5305 | Function Loss:  -0.114\n",
      "Total loss:  1.0445 | PDE Loss:  0.5305 | Function Loss:  -0.1143\n",
      "Total loss:  1.0442 | PDE Loss:  0.5292 | Function Loss:  -0.1141\n",
      "Total loss:  1.044 | PDE Loss:  0.528 | Function Loss:  -0.1139\n",
      "Total loss:  1.0438 | PDE Loss:  0.5278 | Function Loss:  -0.1141\n",
      "Total loss:  1.0435 | PDE Loss:  0.5268 | Function Loss:  -0.114\n",
      "Total loss:  1.0432 | PDE Loss:  0.5267 | Function Loss:  -0.1144\n",
      "Total loss:  1.043 | PDE Loss:  0.5271 | Function Loss:  -0.115\n",
      "Total loss:  1.0427 | PDE Loss:  0.5264 | Function Loss:  -0.1151\n",
      "Total loss:  1.0424 | PDE Loss:  0.5213 | Function Loss:  -0.1133\n",
      "Total loss:  1.0421 | PDE Loss:  0.5275 | Function Loss:  -0.1164\n",
      "Total loss:  1.0419 | PDE Loss:  0.5203 | Function Loss:  -0.1135\n",
      "Total loss:  1.0418 | PDE Loss:  0.5212 | Function Loss:  -0.1141\n",
      "Total loss:  1.0416 | PDE Loss:  0.5201 | Function Loss:  -0.1139\n",
      "Total loss:  1.0414 | PDE Loss:  0.52 | Function Loss:  -0.1142\n",
      "Total loss:  1.041 | PDE Loss:  0.5205 | Function Loss:  -0.1148\n",
      "Total loss:  1.0407 | PDE Loss:  0.5222 | Function Loss:  -0.1161\n",
      "Total loss:  1.0403 | PDE Loss:  0.5205 | Function Loss:  -0.1159\n",
      "Total loss:  1.0399 | PDE Loss:  0.52 | Function Loss:  -0.1162\n",
      "Total loss:  1.0395 | PDE Loss:  0.5193 | Function Loss:  -0.1165\n",
      "Total loss:  1.0392 | PDE Loss:  0.5175 | Function Loss:  -0.1162\n",
      "Total loss:  1.0388 | PDE Loss:  0.5194 | Function Loss:  -0.1176\n",
      "Total loss:  1.0385 | PDE Loss:  0.5193 | Function Loss:  -0.118\n",
      "Total loss:  1.0381 | PDE Loss:  0.5278 | Function Loss:  -0.1224\n",
      "Total loss:  1.0377 | PDE Loss:  0.5261 | Function Loss:  -0.1221\n",
      "Total loss:  1.0374 | PDE Loss:  0.5269 | Function Loss:  -0.123\n",
      "Total loss:  1.037 | PDE Loss:  0.5306 | Function Loss:  -0.1252\n",
      "Total loss:  1.0367 | PDE Loss:  0.5254 | Function Loss:  -0.1233\n",
      "Total loss:  1.0364 | PDE Loss:  0.5322 | Function Loss:  -0.1267\n",
      "Total loss:  1.0362 | PDE Loss:  0.532 | Function Loss:  -0.127\n",
      "Total loss:  1.0359 | PDE Loss:  0.5283 | Function Loss:  -0.1257\n",
      "Total loss:  1.0357 | PDE Loss:  0.5299 | Function Loss:  -0.1267\n",
      "Total loss:  1.0355 | PDE Loss:  0.5293 | Function Loss:  -0.1267\n",
      "Total loss:  1.0353 | PDE Loss:  0.5316 | Function Loss:  -0.1281\n",
      "Total loss:  1.0351 | PDE Loss:  0.5317 | Function Loss:  -0.1285\n",
      "Total loss:  1.0348 | PDE Loss:  0.5306 | Function Loss:  -0.1283\n",
      "Total loss:  1.0346 | PDE Loss:  0.5277 | Function Loss:  -0.1273\n",
      "Total loss:  1.0343 | PDE Loss:  0.5271 | Function Loss:  -0.1275\n",
      "Total loss:  1.0339 | PDE Loss:  0.521 | Function Loss:  -0.1254\n",
      "Total loss:  1.0335 | PDE Loss:  0.5204 | Function Loss:  -0.1257\n",
      "Total loss:  1.0331 | PDE Loss:  0.515 | Function Loss:  -0.1239\n",
      "Total loss:  1.0327 | PDE Loss:  0.5124 | Function Loss:  -0.1234\n",
      "Total loss:  1.0323 | PDE Loss:  0.511 | Function Loss:  -0.1233\n",
      "Total loss:  1.0319 | PDE Loss:  0.5077 | Function Loss:  -0.1224\n",
      "Total loss:  1.0317 | PDE Loss:  0.509 | Function Loss:  -0.1233\n",
      "Total loss:  1.0314 | PDE Loss:  0.507 | Function Loss:  -0.1229\n",
      "Total loss:  1.031 | PDE Loss:  0.5126 | Function Loss:  -0.1258\n",
      "Total loss:  1.0306 | PDE Loss:  0.5097 | Function Loss:  -0.1251\n",
      "Total loss:  1.0303 | PDE Loss:  0.5112 | Function Loss:  -0.1262\n",
      "Total loss:  1.03 | PDE Loss:  0.5099 | Function Loss:  -0.1261\n",
      "Total loss:  1.0297 | PDE Loss:  0.5094 | Function Loss:  -0.1263\n",
      "Total loss:  1.0295 | PDE Loss:  0.5094 | Function Loss:  -0.1266\n",
      "Total loss:  1.0292 | PDE Loss:  0.5104 | Function Loss:  -0.1275\n",
      "Total loss:  1.0291 | PDE Loss:  0.509 | Function Loss:  -0.127\n",
      "Total loss:  1.0288 | PDE Loss:  0.5146 | Function Loss:  -0.1299\n",
      "Total loss:  1.0286 | PDE Loss:  0.5117 | Function Loss:  -0.1289\n",
      "Total loss:  1.0285 | PDE Loss:  0.5131 | Function Loss:  -0.1296\n",
      "Total loss:  1.0283 | PDE Loss:  0.5138 | Function Loss:  -0.1302\n",
      "Total loss:  1.028 | PDE Loss:  0.5142 | Function Loss:  -0.1308\n",
      "Total loss:  1.0277 | PDE Loss:  0.5174 | Function Loss:  -0.1328\n",
      "Total loss:  1.0273 | PDE Loss:  0.5179 | Function Loss:  -0.1336\n",
      "Total loss:  1.027 | PDE Loss:  0.5163 | Function Loss:  -0.1333\n",
      "Total loss:  1.0263 | PDE Loss:  0.512 | Function Loss:  -0.1323\n",
      "Total loss:  1.0259 | PDE Loss:  0.5096 | Function Loss:  -0.1319\n",
      "Total loss:  1.0254 | PDE Loss:  0.5015 | Function Loss:  -0.1291\n",
      "Total loss:  1.0249 | PDE Loss:  0.5013 | Function Loss:  -0.1297\n",
      "Total loss:  1.0245 | PDE Loss:  0.4913 | Function Loss:  -0.1261\n",
      "Total loss:  1.0241 | PDE Loss:  0.4894 | Function Loss:  -0.1258\n",
      "Total loss:  1.0238 | PDE Loss:  0.488 | Function Loss:  -0.1257\n",
      "Total loss:  1.0234 | PDE Loss:  0.4798 | Function Loss:  -0.1229\n",
      "Total loss:  1.0231 | PDE Loss:  0.4837 | Function Loss:  -0.1249\n",
      "Total loss:  1.0229 | PDE Loss:  0.4795 | Function Loss:  -0.1235\n",
      "Total loss:  1.0227 | PDE Loss:  0.4824 | Function Loss:  -0.125\n",
      "Total loss:  1.0224 | PDE Loss:  0.4787 | Function Loss:  -0.1239\n",
      "Total loss:  1.0222 | PDE Loss:  0.4817 | Function Loss:  -0.1254\n",
      "Total loss:  1.022 | PDE Loss:  0.4818 | Function Loss:  -0.1257\n",
      "Total loss:  1.0218 | PDE Loss:  0.4832 | Function Loss:  -0.1265\n",
      "Total loss:  1.0216 | PDE Loss:  0.4841 | Function Loss:  -0.1272\n",
      "Total loss:  1.0213 | PDE Loss:  0.4829 | Function Loss:  -0.1271\n",
      "Total loss:  1.0211 | PDE Loss:  0.4816 | Function Loss:  -0.1269\n",
      "Total loss:  1.0209 | PDE Loss:  0.4826 | Function Loss:  -0.1276\n",
      "Total loss:  1.0207 | PDE Loss:  0.4805 | Function Loss:  -0.1269\n",
      "Total loss:  1.0205 | PDE Loss:  0.4808 | Function Loss:  -0.1274\n",
      "Total loss:  1.0201 | PDE Loss:  0.4806 | Function Loss:  -0.1278\n",
      "Total loss:  1.0197 | PDE Loss:  0.4778 | Function Loss:  -0.1273\n",
      "Total loss:  1.0193 | PDE Loss:  0.4811 | Function Loss:  -0.1293\n",
      "Total loss:  1.0188 | PDE Loss:  0.4778 | Function Loss:  -0.1285\n",
      "Total loss:  1.0184 | PDE Loss:  0.4793 | Function Loss:  -0.1298\n",
      "Total loss:  1.0181 | PDE Loss:  0.4748 | Function Loss:  -0.1284\n",
      "Total loss:  1.0179 | PDE Loss:  0.4762 | Function Loss:  -0.1292\n",
      "Total loss:  1.0177 | PDE Loss:  0.4713 | Function Loss:  -0.1274\n",
      "Total loss:  1.0176 | PDE Loss:  0.4699 | Function Loss:  -0.127\n",
      "Total loss:  1.0174 | PDE Loss:  0.4689 | Function Loss:  -0.1269\n",
      "Total loss:  1.0171 | PDE Loss:  0.4678 | Function Loss:  -0.1269\n",
      "Total loss:  1.0168 | PDE Loss:  0.467 | Function Loss:  -0.127\n",
      "Total loss:  1.0166 | PDE Loss:  0.4691 | Function Loss:  -0.1281\n",
      "Total loss:  1.0163 | PDE Loss:  0.4684 | Function Loss:  -0.1282\n",
      "Total loss:  1.016 | PDE Loss:  0.4719 | Function Loss:  -0.1301\n",
      "Total loss:  1.0156 | PDE Loss:  0.4695 | Function Loss:  -0.1297\n",
      "Total loss:  1.0153 | PDE Loss:  0.472 | Function Loss:  -0.1311\n",
      "Total loss:  1.015 | PDE Loss:  0.4693 | Function Loss:  -0.1305\n",
      "Total loss:  1.0147 | PDE Loss:  0.4708 | Function Loss:  -0.1315\n",
      "Total loss:  1.0143 | PDE Loss:  0.4681 | Function Loss:  -0.1309\n",
      "Total loss:  1.014 | PDE Loss:  0.4656 | Function Loss:  -0.1304\n",
      "Total loss:  1.0137 | PDE Loss:  0.4657 | Function Loss:  -0.1308\n",
      "Total loss:  1.0134 | PDE Loss:  0.4637 | Function Loss:  -0.1306\n",
      "Total loss:  1.013 | PDE Loss:  0.4629 | Function Loss:  -0.1308\n",
      "Total loss:  1.0125 | PDE Loss:  0.4668 | Function Loss:  -0.1329\n",
      "Total loss:  1.0121 | PDE Loss:  0.4632 | Function Loss:  -0.1322\n",
      "Total loss:  1.0117 | PDE Loss:  0.4674 | Function Loss:  -0.1344\n",
      "Total loss:  1.0113 | PDE Loss:  0.4703 | Function Loss:  -0.136\n",
      "Total loss:  1.011 | PDE Loss:  0.4675 | Function Loss:  -0.1354\n",
      "Total loss:  1.0107 | PDE Loss:  0.473 | Function Loss:  -0.138\n",
      "Total loss:  1.0105 | PDE Loss:  0.4704 | Function Loss:  -0.1372\n",
      "Total loss:  1.0103 | PDE Loss:  0.4662 | Function Loss:  -0.1358\n",
      "Total loss:  1.0101 | PDE Loss:  0.4649 | Function Loss:  -0.1356\n",
      "Total loss:  1.0098 | PDE Loss:  0.4587 | Function Loss:  -0.1336\n",
      "Total loss:  1.0095 | PDE Loss:  0.4558 | Function Loss:  -0.1329\n",
      "Total loss:  1.009 | PDE Loss:  0.4504 | Function Loss:  -0.1314\n",
      "Total loss:  1.0085 | PDE Loss:  0.4463 | Function Loss:  -0.1305\n",
      "Total loss:  1.0081 | PDE Loss:  0.4463 | Function Loss:  -0.1312\n",
      "Total loss:  1.0075 | PDE Loss:  0.4422 | Function Loss:  -0.1304\n",
      "Total loss:  1.007 | PDE Loss:  0.4499 | Function Loss:  -0.134\n",
      "Total loss:  1.0066 | PDE Loss:  0.4438 | Function Loss:  -0.1322\n",
      "Total loss:  1.0063 | PDE Loss:  0.4506 | Function Loss:  -0.1353\n",
      "Total loss:  1.006 | PDE Loss:  0.449 | Function Loss:  -0.1351\n",
      "Total loss:  1.0055 | PDE Loss:  0.4523 | Function Loss:  -0.137\n",
      "Total loss:  1.005 | PDE Loss:  0.4476 | Function Loss:  -0.1359\n",
      "Total loss:  1.0046 | PDE Loss:  0.4472 | Function Loss:  -0.1363\n",
      "Total loss:  1.0042 | PDE Loss:  0.4456 | Function Loss:  -0.1363\n",
      "Total loss:  1.0037 | PDE Loss:  0.447 | Function Loss:  -0.1375\n",
      "Total loss:  1.0033 | PDE Loss:  0.4458 | Function Loss:  -0.1375\n",
      "Total loss:  1.0031 | PDE Loss:  0.4499 | Function Loss:  -0.1394\n",
      "Total loss:  1.0029 | PDE Loss:  0.4523 | Function Loss:  -0.1406\n",
      "Total loss:  1.0027 | PDE Loss:  0.4531 | Function Loss:  -0.1412\n",
      "Total loss:  1.0024 | PDE Loss:  0.4532 | Function Loss:  -0.1417\n",
      "Total loss:  1.002 | PDE Loss:  0.456 | Function Loss:  -0.1433\n",
      "Total loss:  1.0018 | PDE Loss:  0.4541 | Function Loss:  -0.1429\n",
      "Total loss:  1.0015 | PDE Loss:  0.454 | Function Loss:  -0.1432\n",
      "Total loss:  1.0013 | PDE Loss:  0.4527 | Function Loss:  -0.1431\n",
      "Total loss:  1.001 | PDE Loss:  0.452 | Function Loss:  -0.1432\n",
      "Total loss:  1.0006 | PDE Loss:  0.4501 | Function Loss:  -0.1429\n",
      "Total loss:  1.0002 | PDE Loss:  0.4505 | Function Loss:  -0.1436\n",
      "Total loss:  0.9999 | PDE Loss:  0.4457 | Function Loss:  -0.1423\n",
      "Total loss:  0.9996 | PDE Loss:  0.4471 | Function Loss:  -0.1433\n",
      "Total loss:  0.9992 | PDE Loss:  0.4448 | Function Loss:  -0.1429\n",
      "Total loss:  0.9989 | PDE Loss:  0.4462 | Function Loss:  -0.1439\n",
      "Total loss:  0.9985 | PDE Loss:  0.4464 | Function Loss:  -0.1444\n",
      "Total loss:  0.998 | PDE Loss:  0.4476 | Function Loss:  -0.1456\n",
      "Total loss:  0.9976 | PDE Loss:  0.4469 | Function Loss:  -0.146\n",
      "Total loss:  0.9967 | PDE Loss:  0.4494 | Function Loss:  -0.1481\n",
      "Total loss:  0.996 | PDE Loss:  0.4479 | Function Loss:  -0.1486\n",
      "Total loss:  0.9954 | PDE Loss:  0.4426 | Function Loss:  -0.1473\n",
      "Total loss:  0.9948 | PDE Loss:  0.4439 | Function Loss:  -0.1486\n",
      "Total loss:  0.9942 | PDE Loss:  0.443 | Function Loss:  -0.1491\n",
      "Total loss:  0.9937 | PDE Loss:  0.4393 | Function Loss:  -0.1484\n",
      "Total loss:  0.9933 | PDE Loss:  0.4395 | Function Loss:  -0.149\n",
      "Total loss:  0.993 | PDE Loss:  0.4408 | Function Loss:  -0.15\n",
      "Total loss:  0.9927 | PDE Loss:  0.4383 | Function Loss:  -0.1493\n",
      "Total loss:  0.9925 | PDE Loss:  0.4331 | Function Loss:  -0.1476\n",
      "Total loss:  0.9923 | PDE Loss:  0.4329 | Function Loss:  -0.1478\n",
      "Total loss:  0.9919 | PDE Loss:  0.4302 | Function Loss:  -0.1473\n",
      "Total loss:  0.9914 | PDE Loss:  0.4255 | Function Loss:  -0.1463\n",
      "Total loss:  0.9908 | PDE Loss:  0.4301 | Function Loss:  -0.1488\n",
      "Total loss:  0.9904 | PDE Loss:  0.4223 | Function Loss:  -0.1465\n",
      "Total loss:  0.99 | PDE Loss:  0.4251 | Function Loss:  -0.1481\n",
      "Total loss:  0.9894 | PDE Loss:  0.4223 | Function Loss:  -0.1478\n",
      "Total loss:  0.9888 | PDE Loss:  0.4292 | Function Loss:  -0.1512\n",
      "Total loss:  0.9883 | PDE Loss:  0.4251 | Function Loss:  -0.1504\n",
      "Total loss:  0.9879 | PDE Loss:  0.4293 | Function Loss:  -0.1526\n",
      "Total loss:  0.9875 | PDE Loss:  0.4297 | Function Loss:  -0.1533\n",
      "Total loss:  0.987 | PDE Loss:  0.4276 | Function Loss:  -0.1532\n",
      "Total loss:  0.9864 | PDE Loss:  0.4264 | Function Loss:  -0.1535\n",
      "Total loss:  0.986 | PDE Loss:  0.4157 | Function Loss:  -0.1501\n",
      "Total loss:  0.9856 | PDE Loss:  0.4154 | Function Loss:  -0.1504\n",
      "Total loss:  0.9854 | PDE Loss:  0.4133 | Function Loss:  -0.15\n",
      "Total loss:  0.985 | PDE Loss:  0.4071 | Function Loss:  -0.1483\n",
      "Total loss:  0.9847 | PDE Loss:  0.4036 | Function Loss:  -0.1475\n",
      "Total loss:  0.9842 | PDE Loss:  0.41 | Function Loss:  -0.1504\n",
      "Total loss:  0.9839 | PDE Loss:  0.4102 | Function Loss:  -0.1509\n",
      "Total loss:  0.9836 | PDE Loss:  0.4108 | Function Loss:  -0.1515\n",
      "Total loss:  0.9834 | PDE Loss:  0.4129 | Function Loss:  -0.1526\n",
      "Total loss:  0.983 | PDE Loss:  0.417 | Function Loss:  -0.1546\n",
      "Total loss:  0.9826 | PDE Loss:  0.4195 | Function Loss:  -0.1561\n",
      "Total loss:  0.9823 | PDE Loss:  0.4166 | Function Loss:  -0.1555\n",
      "Total loss:  0.9819 | PDE Loss:  0.4175 | Function Loss:  -0.1564\n",
      "Total loss:  0.9815 | PDE Loss:  0.4115 | Function Loss:  -0.1547\n",
      "Total loss:  0.9812 | PDE Loss:  0.4091 | Function Loss:  -0.1542\n",
      "Total loss:  0.9809 | PDE Loss:  0.407 | Function Loss:  -0.1538\n",
      "Total loss:  0.9805 | PDE Loss:  0.4043 | Function Loss:  -0.1534\n",
      "Total loss:  0.98 | PDE Loss:  0.4033 | Function Loss:  -0.1537\n",
      "Total loss:  0.9796 | PDE Loss:  0.4003 | Function Loss:  -0.1532\n",
      "Total loss:  0.9792 | PDE Loss:  0.4027 | Function Loss:  -0.1546\n",
      "Total loss:  0.9789 | PDE Loss:  0.403 | Function Loss:  -0.155\n",
      "Total loss:  0.9786 | PDE Loss:  0.4006 | Function Loss:  -0.1546\n",
      "Total loss:  0.9782 | PDE Loss:  0.4055 | Function Loss:  -0.157\n",
      "Total loss:  0.9778 | PDE Loss:  0.4058 | Function Loss:  -0.1576\n",
      "Total loss:  0.9772 | PDE Loss:  0.4066 | Function Loss:  -0.1587\n",
      "Total loss:  0.9766 | PDE Loss:  0.4133 | Function Loss:  -0.1621\n",
      "Total loss:  0.9761 | PDE Loss:  0.4139 | Function Loss:  -0.1629\n",
      "Total loss:  0.9758 | PDE Loss:  0.4124 | Function Loss:  -0.1629\n",
      "Total loss:  0.9754 | PDE Loss:  0.4144 | Function Loss:  -0.1641\n",
      "Total loss:  0.9752 | PDE Loss:  0.4131 | Function Loss:  -0.1639\n",
      "Total loss:  0.9749 | PDE Loss:  0.4122 | Function Loss:  -0.164\n",
      "Total loss:  0.9745 | PDE Loss:  0.4167 | Function Loss:  -0.1663\n",
      "Total loss:  0.9741 | PDE Loss:  0.4113 | Function Loss:  -0.1648\n",
      "Total loss:  0.9738 | PDE Loss:  0.4132 | Function Loss:  -0.1659\n",
      "Total loss:  0.9735 | PDE Loss:  0.4129 | Function Loss:  -0.1661\n",
      "Total loss:  0.9733 | PDE Loss:  0.4128 | Function Loss:  -0.1664\n",
      "Total loss:  0.9731 | PDE Loss:  0.4143 | Function Loss:  -0.1673\n",
      "Total loss:  0.9728 | PDE Loss:  0.4154 | Function Loss:  -0.1681\n",
      "Total loss:  0.9726 | PDE Loss:  0.4147 | Function Loss:  -0.1682\n",
      "Total loss:  0.9723 | PDE Loss:  0.418 | Function Loss:  -0.1698\n",
      "Total loss:  0.9721 | PDE Loss:  0.418 | Function Loss:  -0.17\n",
      "Total loss:  0.9718 | PDE Loss:  0.4209 | Function Loss:  -0.1716\n",
      "Total loss:  0.9715 | PDE Loss:  0.4207 | Function Loss:  -0.1719\n",
      "Total loss:  0.9712 | PDE Loss:  0.4225 | Function Loss:  -0.173\n",
      "Total loss:  0.9709 | PDE Loss:  0.4226 | Function Loss:  -0.1736\n",
      "Total loss:  0.9704 | PDE Loss:  0.4213 | Function Loss:  -0.1737\n",
      "Total loss:  0.97 | PDE Loss:  0.4302 | Function Loss:  -0.1778\n",
      "Total loss:  0.9697 | PDE Loss:  0.4245 | Function Loss:  -0.1759\n",
      "Total loss:  0.9695 | PDE Loss:  0.4224 | Function Loss:  -0.1754\n",
      "Total loss:  0.9693 | PDE Loss:  0.4204 | Function Loss:  -0.1749\n",
      "Total loss:  0.9691 | PDE Loss:  0.4185 | Function Loss:  -0.1745\n",
      "Total loss:  0.9689 | PDE Loss:  0.4163 | Function Loss:  -0.1739\n",
      "Total loss:  0.9686 | PDE Loss:  0.4171 | Function Loss:  -0.1746\n",
      "Total loss:  0.9683 | PDE Loss:  0.4148 | Function Loss:  -0.1742\n",
      "Total loss:  0.968 | PDE Loss:  0.4159 | Function Loss:  -0.175\n",
      "Total loss:  0.9677 | PDE Loss:  0.4172 | Function Loss:  -0.1759\n",
      "Total loss:  0.9673 | PDE Loss:  0.4186 | Function Loss:  -0.177\n",
      "Total loss:  0.9669 | PDE Loss:  0.4193 | Function Loss:  -0.1778\n",
      "Total loss:  0.9667 | PDE Loss:  0.421 | Function Loss:  -0.1788\n",
      "Total loss:  0.9665 | PDE Loss:  0.4212 | Function Loss:  -0.1791\n",
      "Total loss:  0.9663 | PDE Loss:  0.4212 | Function Loss:  -0.1793\n",
      "Total loss:  0.966 | PDE Loss:  0.4204 | Function Loss:  -0.1794\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hist = pinn.fit(num_epochs=n_epochs,\n",
    "                optimizer=optimizer_LBFGS,\n",
    "                verbose=True)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(np.arange(1, len(hist) + 1), hist, label=\"Train Loss\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1\n",
    "x = 0\n",
    "# inputs [t, x]\n",
    "inputs = torch.tensor([t, x], dtype=torch.float, requires_grad=True)\n",
    "output = pinn.approximate_solution(inputs).reshape(-1, )\n",
    "\n",
    "print(\"inputs: \", inputs)\n",
    "print(\"output: \", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tf = output[0]\n",
    "Ts = output[1]\n",
    "t = inputs[0]\n",
    "x = inputs[1]\n",
    "dTf_dx = torch.autograd.grad(Ts, inputs, create_graph=True)[0][1]\n",
    "dTf_dx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Boundary conditions\n",
    "\n",
    "Here we are going to evaluate the pinn output at the points where we have the boundary conditions and we will verify manually thet they correspond to the correct one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = pinn.domain_extrema[1, 0]\n",
    "xL = pinn.domain_extrema[1, 1]\n",
    "\n",
    "input_sb = pinn.soboleng.draw(10)\n",
    "input_sb.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_sb = pinn.soboleng.draw(10)\n",
    "# input_sb.requires_grad_()\n",
    "\n",
    "# # T=0\n",
    "# x0_t0 = pinn.domain_extrema[0, 0]\n",
    "# xL_t0 = pinn.domain_extrema[0, 1]\n",
    "\n",
    "# input_sb_0_t0 = torch.clone(input_sb)\n",
    "# input_sb_0_t0[:, 1] = torch.full(input_sb_0_t0[:, 1].shape, x0_t0)\n",
    "\n",
    "# input_sb_L_t0 = torch.clone(input_sb)\n",
    "# input_sb_L_t0[:, 1] = torch.full(input_sb_L_t0[:, 1].shape, xL_t0)\n",
    "\n",
    "# # T=1\n",
    "# x0_t1 = pinn.domain_extrema[1, 0]\n",
    "# xL_t1 = pinn.domain_extrema[1, 1]\n",
    "\n",
    "# input_sb_0_t1 = torch.clone(input_sb)\n",
    "# input_sb_0_t1[:, 1] = torch.full(input_sb_0_t1[:, 1].shape, x0_t1)\n",
    "\n",
    "# input_sb_L_t1 = torch.clone(input_sb)\n",
    "# input_sb_L_t1[:, 1] = torch.full(input_sb_L_t1[:, 1].shape, xL_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = pinn.domain_extrema[1, 0]\n",
    "xL = pinn.domain_extrema[1, 1]\n",
    "\n",
    "input_sb = pinn.soboleng.draw(10)\n",
    "input_sb.requires_grad_()\n",
    "\n",
    "input_sb_0 = torch.clone(input_sb)\n",
    "input_sb_0[:, 1] = torch.full(input_sb_0[:, 1].shape, x0)\n",
    "\n",
    "input_sb_L = torch.clone(input_sb)\n",
    "input_sb_L[:, 1] = torch.full(input_sb_L[:, 1].shape, xL)\n",
    "\n",
    "print(\"input_sb_0: \\n\", input_sb_0)\n",
    "print()\n",
    "print(\"input_sb_L: \\n\", input_sb_L)\n",
    "\n",
    "print()\n",
    "print(\"----------------------------------------------\")\n",
    "print()\n",
    "\n",
    "T_0 = pinn.approximate_solution(input_sb_0)\n",
    "Tf_0 = T_0[:,0]\n",
    "Ts_0 = T_0[:,1]\n",
    "dTs_0_dx = torch.autograd.grad(Ts_0.sum(), input_sb_0, create_graph=True)[0][:, 1]\n",
    "\n",
    "T_L = pinn.approximate_solution(input_sb_L)\n",
    "Tf_L = T_L[:,0]\n",
    "Ts_L = T_L[:,1]\n",
    "\n",
    "dTf_L_dx = torch.autograd.grad(Tf_L.sum(), input_sb_L, create_graph=True)[0][:, 1]\n",
    "dTs_L_dx = torch.autograd.grad(Ts_L.sum(), input_sb_L, create_graph=True)[0][:, 1]\n",
    "\n",
    "print(\"dTs_0_dx: \\n\", dTs_0_dx.reshape(-1,1))\n",
    "print()\n",
    "print(\"dTf_L_dx: \\n\", dTf_L_dx.reshape(-1,1))\n",
    "print()\n",
    "print(\"dTs_L_dx: \\n\", dTs_L_dx.reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "# output_sb_0 = ((pinn.T_hot-pinn.T_0)/(1+torch.exp(-200*(input_sb-0.25)))+pinn.T_0)  # is a tensor with two columns [T_f, T_s], however we will just want to use the first one\n",
    "# output_sb_0\n",
    "# save_expected = output_sb_0[:,0]\n",
    "# save_expected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this other block we are going to call the function that applies the boundary conditions.\n",
    "\n",
    "Note that the output will be $ [T_f, T_s] $ and the 3 conditions are concatenated.\n",
    "\n",
    "Finally note that the values $ 777 $ are for the vacant conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn.apply_boundary_conditions(torch.cat([input_sb_0, input_sb_0, input_sb_L],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the output training_set_sb section 1--> Tf_0\n",
    "for input, output in pinn.training_set_sb:\n",
    "    print(output[:int(output.shape[0]/3), :].shape)\n",
    "    print(output[:int(output.shape[0]/3), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the output training_set_sb section 2--> Ts_0_dx\n",
    "for input, output in pinn.training_set_sb:\n",
    "    print(output[int(output.shape[0]/3):int(2*output.shape[0]/3), :].shape)\n",
    "    print(output[int(output.shape[0]/3):int(2*output.shape[0]/3), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the output training_set_sb section 3--> Tf/s_0_dx\n",
    "for input, output in pinn.training_set_sb:\n",
    "    print(output[int(2*output.shape[0]/3):, :].shape)\n",
    "    print(output[int(2*output.shape[0]/3):, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, output in pinn.training_set_sb:\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasterThesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
