{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on  mps\n"
     ]
    }
   ],
   "source": [
    "from Class_PINN_FBPINN import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing number of subdomains and layers in PINN for multi-scale problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "domain = [-2*torch.pi, 2*torch.pi]\n",
    "\n",
    "n_multi_scale = 5\n",
    "w_list = [2, 4, 8, 16, 32]\n",
    "overlap = 0.3\n",
    "sigma = 0.1\n",
    "n_hidden_layers = 2\n",
    "neurons = 16\n",
    "\n",
    "#n_subdomains = 30\n",
    "\n",
    "num_points = 200*15\n",
    "# n_epochs = 10000\n",
    "n_epochs = 5000\n",
    "\n",
    "n_subdomains = [10,30,50,100]\n",
    "# n_subdomains = [10, 30, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_loss_arr = []\n",
    "l1_loss_min = []\n",
    "loss_domains = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution():\n",
    "    # Plot the exact solution\n",
    "    x = torch.linspace(domain[0], domain[1], num_points, dtype=torch.float32, device=DEVICE).reshape(-1, 1)\n",
    "    u_exact = model.exact_solution(x)\n",
    "\n",
    "    plt.plot(x.cpu().detach().numpy(), u_exact.cpu().detach().numpy(), label='Exact', color=\"blue\")\n",
    "\n",
    "    # Plot the FBPINN solution\n",
    "    for i in range(model.n_subdomains):\n",
    "        subdomain_i = model.subdomains[i]\n",
    "        NN_i = model.neural_networks[i]\n",
    "        NN_i.eval()\n",
    "\n",
    "    u_approx = torch.tanh(model.w_list[-1] * x) * model(x)\n",
    "\n",
    "    plt.plot(x.cpu().detach().numpy(), u_approx.cpu().detach().numpy(), color=\"green\")\n",
    "    # Add label only once\n",
    "    if i == 0:\n",
    "        plt.plot(x.cpu().detach().numpy(), u_approx.cpu().detach().numpy(), label='FBPINN', color=\"green\")\n",
    "    plt.title('FBPINN (full solution)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tanh' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m mps_device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m nr_sub \u001b[39min\u001b[39;00m n_subdomains:\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m     \u001b[39m# Create the model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     model \u001b[39m=\u001b[39m FBPINN_Cos_nD(domain_extrema\u001b[39m=\u001b[39;49mdomain, n_subdomains\u001b[39m=\u001b[39;49mnr_sub, overlap\u001b[39m=\u001b[39;49moverlap, sigma\u001b[39m=\u001b[39;49msigma, n_hidden_layers\u001b[39m=\u001b[39;49mn_hidden_layers, neurons\u001b[39m=\u001b[39;49mneurons, activation_function\u001b[39m=\u001b[39;49mnn\u001b[39m.\u001b[39;49mTanh(), n_multi_scale\u001b[39m=\u001b[39;49mn_multi_scale, w_list\u001b[39m=\u001b[39;49mw_list)\n\u001b[1;32m      8\u001b[0m     \u001b[39m# Train the FBPINN\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     model\u001b[39m.\u001b[39mto(mps_device)\n",
      "File \u001b[0;32m~/Documents/UNIVERSITY/ETH_Master/Gugo_DLSC/DeepLearning/Task_B/Final_Version/Class_PINN_FBPINN.py:76\u001b[0m, in \u001b[0;36mFBPINN_Cos_nD.__init__\u001b[0;34m(self, domain_extrema, n_subdomains, overlap, sigma, n_hidden_layers, neurons, activation_function, n_multi_scale, w_list)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39m# The activation function\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_function \u001b[39m=\u001b[39m activation_function\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 76\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation_function\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     79\u001b[0m \u001b[39m# The frequencies of the problem\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39massert\u001b[39;00m n_multi_scale \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(w_list), \u001b[39m\"\u001b[39m\u001b[39mNumber of frequecies w do not match the number of multi-scale\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1591\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1590\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1591\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1592\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tanh' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "mps_device = torch.device(\"mps\")\n",
    "\n",
    "for nr_sub in n_subdomains:\n",
    "\n",
    "    # Create the model\n",
    "    model = FBPINN_Cos_nD(domain_extrema=domain, n_subdomains=nr_sub, overlap=overlap, sigma=sigma, n_hidden_layers=n_hidden_layers, neurons=neurons, activation_function=nn.Tanh(), n_multi_scale=n_multi_scale, w_list=w_list)\n",
    "\n",
    "    # Train the FBPINN\n",
    "    model.to(mps_device)\n",
    "    history, l1_loss = model.fit(num_points, n_epochs, verbose=False)\n",
    "\n",
    "    l1_loss_arr.append(l1_loss)\n",
    "\n",
    "    print(\"Loss: {}\".format(np.min(l1_loss)))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plot_solution()\n",
    "\n",
    "    torch.save(model.state_dict(), 'models_save/scale_fbpinn_{}.pdh'.format(nr_sub))\n",
    "\n",
    "    # Save the l1 loss in pickle\n",
    "    with open(\"l1_loss_scale_fbpinn_{}\".format(nr_sub), 'wb') as file:\n",
    "        pickle.dump(l1_loss, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "domain = [-2*torch.pi, 2*torch.pi]\n",
    "\n",
    "n_multi_scale = 3\n",
    "w_list = [1, 4, 15]\n",
    "n_subdomains = 30\n",
    "overlap = 0.3\n",
    "sigma = 0.1\n",
    "n_hidden_layers = 2\n",
    "neurons = 16\n",
    "\n",
    "# Create the model\n",
    "fbpinn = FBPINN_Cos_nD(domain_extrema=domain, n_subdomains=n_subdomains, overlap=overlap, sigma=sigma, n_hidden_layers=n_hidden_layers, neurons=neurons, activation_function=nn.Tanh(), n_multi_scale=n_multi_scale, w_list=w_list)\n",
    "\n",
    "# Train the FBPINN\n",
    "num_points = 200*15\n",
    "n_epochs = 10000\n",
    "\n",
    "history = fbpinn.fit(num_points, n_epochs, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
